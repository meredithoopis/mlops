{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading Open Images annotations if needed...\n",
      "Finding class IDs for target vehicle classes...\n",
      "Found bus class ID: /m/01bjv\n",
      "Found truck class ID: /m/07r04\n",
      "Found car class ID: /m/0k4j\n",
      "Found taxi class ID: /m/0pg52\n",
      "Reading annotations and categorizing images by vehicle class...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15it [00:48,  3.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 89465 images with car\n",
      "Found 1434 images with taxi\n",
      "Found 7293 images with bus\n",
      "Found 8078 images with truck\n",
      "Selected 1000 images for car\n",
      "Selected 1000 images for truck\n",
      "Selected 1000 images for bus\n",
      "Selected 1000 images for taxi\n",
      "Total selected images: 4000\n",
      "Image IDs saved to vehicle_images.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading images: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4000/4000 [04:05<00:00, 16.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded 4000 of 4000 images\n",
      "Successful downloads list saved to vehicle_images_successful.txt\n",
      "Reading image IDs...\n",
      "Found 4000 unique image IDs\n",
      "Loading class descriptions...\n",
      "Found 4 target vehicle class IDs\n",
      "Extracting vehicle labels for your images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15it [00:22,  1.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Class distribution in the dataset:\n",
      "LabelName_Text\n",
      "Car      5368\n",
      "Taxi     2913\n",
      "Bus      1735\n",
      "Truck    1565\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Class weights (for balanced training):\n",
      "Car: 0.5394\n",
      "Taxi: 0.9939\n",
      "Bus: 1.6687\n",
      "Truck: 1.8500\n",
      "\n",
      "Found 11581 vehicle annotations for 4000 images\n",
      "Labels saved to vehicle_labels.csv\n",
      "Final dataset statistics saved to dataset_stats.json\n"
     ]
    }
   ],
   "source": [
    "# import csv\n",
    "# import os\n",
    "# import random\n",
    "# import boto3\n",
    "# import botocore\n",
    "# import tqdm\n",
    "# from concurrent import futures\n",
    "# import pandas as pd\n",
    "# import re\n",
    "# import sys\n",
    "\n",
    "# #Rec: Take 5000 from the beginning \n",
    "\n",
    "# # Constants\n",
    "# BUCKET_NAME = 'open-images-dataset'\n",
    "# REGEX = r'(test|train|validation|challenge2018)/([a-fA-F0-9]*)'\n",
    "\n",
    "# ###################################\n",
    "# # Step 1: #From a large dataset, find all images with at least 2 cars and write their IDs to a file -> car_images.txt\n",
    "# ###################################\n",
    "# def find_images_with_multiple_cars(output_file=\"car_images.txt\",subset_size=5000, seed=1610):\n",
    "#     \"\"\"\n",
    "#     Find all images in the Open Images training set with at least 2 cars and\n",
    "#     write their IDs to a file in the format 'train/$id'.\n",
    "    \n",
    "#     Args:\n",
    "#         output_file: Path to the output file where image IDs will be saved\n",
    "#     \"\"\"\n",
    "#     print(\"Downloading Open Images annotations if needed...\")\n",
    "    \n",
    "#     # Paths to annotation files\n",
    "#     class_labels_file = \"class-descriptions-boxable.csv\"\n",
    "#     train_annotations_file = \"train-annotations-bbox.csv\"\n",
    "    \n",
    "#     # Download the class descriptions if needed\n",
    "#     if not os.path.exists(class_labels_file):\n",
    "#         print(f\"Downloading {class_labels_file}...\")\n",
    "#         os.system(f\"wget https://storage.googleapis.com/openimages/v5/class-descriptions-boxable.csv\")\n",
    "        \n",
    "        \n",
    "#     # Download the training annotations if needed\n",
    "#     if not os.path.exists(train_annotations_file):\n",
    "#         print(f\"Downloading {train_annotations_file}...\")\n",
    "#         os.system(f\"wget https://storage.googleapis.com/openimages/2018_04/train/train-annotations-bbox.csv\")\n",
    "    \n",
    "#     # Get the class ID for 'Car'\n",
    "#     car_class_id = None\n",
    "#     print(\"Finding car class ID...\")\n",
    "#     with open(class_labels_file, 'r') as f:\n",
    "#         reader = csv.reader(f)\n",
    "#         for row in reader:\n",
    "#             if row[1].lower() == 'car':\n",
    "#                 car_class_id = row[0]\n",
    "#                 break\n",
    "    \n",
    "#     if not car_class_id:\n",
    "#         print(\"Error: Could not find class ID for 'Car'\")\n",
    "#         return\n",
    "    \n",
    "#     print(f\"Car class ID: {car_class_id}\")\n",
    "    \n",
    "#     # Count car occurrences per image\n",
    "#     print(\"Reading annotations and counting cars per image...\")\n",
    "#     car_counts = {}\n",
    "    \n",
    "#     # Read the annotations file in chunks to handle its large size\n",
    "#     chunk_size = 1000000\n",
    "#     for chunk in tqdm.tqdm(pd.read_csv(train_annotations_file, chunksize=chunk_size)):\n",
    "#         # Filter to only car annotations\n",
    "#         car_annotations = chunk[chunk['LabelName'] == car_class_id]\n",
    "        \n",
    "#         # Count cars per image\n",
    "#         for image_id in car_annotations['ImageID']:\n",
    "#             car_counts[image_id] = car_counts.get(image_id, 0) + 1\n",
    "    \n",
    "#     # Filter images with at least 2 cars\n",
    "#     images_with_multiple_cars = [img_id for img_id, count in car_counts.items() if count >= 2]\n",
    "    \n",
    "#     print(f\"Found {len(images_with_multiple_cars)} images with at least 2 cars\")\n",
    "    \n",
    "#     # Randomly sample a subset with seed\n",
    "#     if len(images_with_multiple_cars) > subset_size:\n",
    "#         random.seed(seed)\n",
    "#         images_with_multiple_cars = random.sample(images_with_multiple_cars, subset_size)\n",
    "#         print(f\"Randomly selected {subset_size} images with seed={seed}\")\n",
    "\n",
    "#     with open(output_file, 'w') as f:\n",
    "#         for img_id in images_with_multiple_cars:\n",
    "#             f.write(f\"train/{img_id}\\n\")\n",
    "    \n",
    "#     print(f\"Image IDs saved to {output_file}\")\n",
    "#     print(f\"You can now use the downloader script with this file: python downloader.py {output_file}\")\n",
    "    \n",
    "    \n",
    "\n",
    "# ###################################\n",
    "# # Step 2: From the car_images.txt file, download images to the data folder \n",
    "# ###################################\n",
    "# def check_and_homogenize_one_image(image):\n",
    "#   split, image_id = re.match(REGEX, image).groups()\n",
    "#   yield split, image_id\n",
    "\n",
    "# def check_and_homogenize_image_list(image_list):\n",
    "#   for line_number, image in enumerate(image_list):\n",
    "#     try:\n",
    "#       yield from check_and_homogenize_one_image(image)\n",
    "#     except (ValueError, AttributeError):\n",
    "#       raise ValueError(\n",
    "#           f'ERROR in line {line_number} of the image list. The following image '\n",
    "#           f'string is not recognized: \"{image}\".')\n",
    "\n",
    "# def read_image_list_file(image_list_file):\n",
    "#   with open(image_list_file, 'r') as f:\n",
    "#     for line in f:\n",
    "#       yield line.strip().replace('.jpg', '')\n",
    "\n",
    "\n",
    "# def download_one_image(bucket, split, image_id, download_folder):\n",
    "#   try:\n",
    "#     bucket.download_file(f'{split}/{image_id}.jpg',\n",
    "#                          os.path.join(download_folder, f'{image_id}.jpg'))\n",
    "#   except botocore.exceptions.ClientError as exception:\n",
    "#     sys.exit(\n",
    "#         f'ERROR when downloading image `{split}/{image_id}`: {str(exception)}')\n",
    "\n",
    "# def download_all_images(image_list_file, download_folder=\"data\", num_processes=14):\n",
    "#     bucket = boto3.resource('s3', config=botocore.config.Config(signature_version=botocore.UNSIGNED)).Bucket(BUCKET_NAME)\n",
    "\n",
    "#     if not os.path.exists(download_folder):\n",
    "#         os.makedirs(download_folder)\n",
    "#     try:\n",
    "#         image_list = list(check_and_homogenize_image_list(read_image_list_file(image_list_file)))\n",
    "#     except ValueError as exception:\n",
    "#         sys.exit(exception)\n",
    "\n",
    "#     progress_bar = tqdm.tqdm(total=len(image_list), desc='Downloading images', leave=True)\n",
    "#     with futures.ThreadPoolExecutor(max_workers=num_processes) as executor:\n",
    "#         all_futures = [\n",
    "#             executor.submit(download_one_image, bucket, split, image_id, download_folder)\n",
    "#             for (split, image_id) in image_list\n",
    "#         ]\n",
    "#         for future in futures.as_completed(all_futures):\n",
    "#             future.result()\n",
    "#             progress_bar.update(1)\n",
    "#     progress_bar.close()\n",
    "    \n",
    "# ###################################\n",
    "# # Step 3: Given data folder, extract car labels from Open Images dataset -> export to car_labels.csv\n",
    "# ###################################\n",
    "# def extract_car_labels_for_images(image_list_file, output_file=\"car_labels.csv\"):\n",
    "#     \"\"\"\n",
    "#     Extract only car labels for images specified in image_list_file from Open Images dataset.\n",
    "    \n",
    "#     Args:\n",
    "#         image_list_file: File containing image IDs in format 'train/[IMAGE_ID]'\n",
    "#         output_file: Path to save extracted labels \"\"\"\n",
    "#     print(\"Reading image IDs...\")\n",
    "#     # Read image IDs from the file\n",
    "#     image_ids = []\n",
    "#     with open(image_list_file, 'r') as f:\n",
    "#         for line in f:\n",
    "#             # Extract just the ID part from \"train/ID\" format\n",
    "#             parts = line.strip().split('/')\n",
    "#             if len(parts) == 2:\n",
    "#                 image_ids.append(parts[1])\n",
    "\n",
    "#     image_ids_set = set(image_ids)\n",
    "#     print(f\"Found {len(image_ids_set)} unique image IDs\")\n",
    "\n",
    "#     # Check if annotation files exist\n",
    "#     class_desc_file = \"class-descriptions-boxable.csv\"  \n",
    "#     bbox_file = \"train-annotations-bbox.csv\" #Tao sua o day \n",
    "\n",
    "#     if not os.path.exists(class_desc_file):\n",
    "#         print(f\"Please download the class descriptions file first:\")\n",
    "#         print(\"wget https://storage.googleapis.com/openimages/v5/class-descriptions-boxable.csv\")\n",
    "#         return\n",
    "    \n",
    "#     if not os.path.exists(bbox_file):\n",
    "#         print(f\"Please download the bounding box annotations file first:\")\n",
    "#         print(\"wget https://storage.googleapis.com/openimages/v6/oidv6-train-annotations-bbox.csv\")\n",
    "#         return\n",
    "    \n",
    "#     # Load class descriptions\n",
    "#     print(\"Loading class descriptions...\")\n",
    "#     class_descriptions = {}\n",
    "#     car_class_ids = []\n",
    "    \n",
    "#     with open(class_desc_file, 'r') as f:\n",
    "#         reader = csv.reader(f)\n",
    "#         for row in reader:\n",
    "#             class_descriptions[row[0]] = row[1]\n",
    "#             # Identify car-related classes\n",
    "#             if any(car_term in row[1].lower() for car_term in ['car', 'truck', 'taxi', 'bus']):\n",
    "#                 car_class_ids.append(row[0])\n",
    "\n",
    "#     print(f\"Found {len(car_class_ids)} car-related classes\")\n",
    "\n",
    "#     # Process annotations in chunks to handle large file size\n",
    "#     print(\"Extracting car labels for your images...\")\n",
    "#     extracted_labels = []\n",
    "    \n",
    "#     # Process the file in chunks to save memory\n",
    "#     chunk_size = 1000000\n",
    "#     total_labels_found = 0\n",
    "\n",
    "#     for chunk in tqdm.tqdm(pd.read_csv(bbox_file, chunksize=chunk_size)):\n",
    "#         # Filter to only include our image IDs AND car-related classes\n",
    "#         # matching_annotations = chunk[(chunk['ImageID'].isin(image_ids_set)) & \n",
    "#         #                             (chunk['LabelName'].isin(car_class_ids))]\n",
    "#         matching_annotations = chunk[(chunk['ImageID'].isin(image_ids_set)) & \n",
    "#                               (chunk['LabelName'].isin(car_class_ids))].copy()\n",
    "\n",
    "        \n",
    "#         if not matching_annotations.empty:\n",
    "#             total_labels_found += len(matching_annotations)\n",
    "#             # Add class name based on LabelName ID\n",
    "#             matching_annotations['LabelName_Text'] = matching_annotations['LabelName'].apply(\n",
    "#                 lambda x: class_descriptions.get(x, 'Unknown'))\n",
    "#             extracted_labels.append(matching_annotations)\n",
    "\n",
    "#     if extracted_labels:\n",
    "#         # Combine all chunks\n",
    "#         all_labels = pd.concat(extracted_labels)\n",
    "        \n",
    "#         # Save to CSV\n",
    "#         all_labels.to_csv(output_file, index=False)\n",
    "        \n",
    "#         print(f\"Found {total_labels_found} car annotations for {len(all_labels['ImageID'].unique())} images\")\n",
    "#         print(f\"Labels saved to {output_file}\")\n",
    "        \n",
    "#         # Show counts by class\n",
    "#         class_counts = all_labels['LabelName_Text'].value_counts()\n",
    "#         print(\"\\nTop 10 car class counts:\")\n",
    "#         print(class_counts.head(10))\n",
    "#     else:\n",
    "#         print(\"No matching car annotations found for your images\")\n",
    "    \n",
    "\n",
    "# ###################################\n",
    "# # Run all steps in order\n",
    "# ###################################\n",
    "# #Set num_processes according to the number of cores in your machine: Download takes 23 mins\n",
    "# if __name__ == \"__main__\":\n",
    "#     find_images_with_multiple_cars(output_file=\"car_images.txt\",subset_size=5000, seed=1610)\n",
    "#     download_all_images(\"car_images.txt\", download_folder=\"data\", num_processes=14)\n",
    "#     extract_car_labels_for_images(\"car_images.txt\")\n",
    "    \n",
    "    \n",
    "#     # Load data \n",
    "#     labels = pd.read_csv(\"car_labels.csv\") \n",
    "#     labels = labels[['ImageID','XMin', 'XMax', 'YMin','YMax', 'LabelName_Text']] \n",
    "#     labels.to_csv(\"car_labels.csv\", index=False)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "#####################################\n",
    "\n",
    "import csv\n",
    "import os\n",
    "import random\n",
    "import boto3\n",
    "import botocore\n",
    "import tqdm\n",
    "from concurrent import futures\n",
    "import pandas as pd\n",
    "import re\n",
    "import sys\n",
    "from collections import defaultdict\n",
    "\n",
    "# Constants\n",
    "BUCKET_NAME = 'open-images-dataset'\n",
    "REGEX = r'(test|train|validation|challenge2018)/([a-fA-F0-9]*)'\n",
    "TARGET_CLASSES = ['car', 'truck', 'bus', 'taxi']\n",
    "\n",
    "###################################\n",
    "# Step 1: Find images with target vehicle classes and write their IDs to a file\n",
    "###################################\n",
    "def find_balanced_vehicle_images(output_file=\"vehicle_images.txt\", images_per_class=1000, seed=1610):\n",
    "    \"\"\"\n",
    "    Find images in the Open Images training set containing the target vehicle classes\n",
    "    and create a balanced dataset with equal representation of each class.\n",
    "    \n",
    "    Args:\n",
    "        output_file: Path to the output file where image IDs will be saved\n",
    "        images_per_class: Number of images to collect per target class\n",
    "        seed: Random seed for reproducibility\n",
    "    \"\"\"\n",
    "    print(\"Downloading Open Images annotations if needed...\")\n",
    "    \n",
    "    # Paths to annotation files\n",
    "    class_labels_file = \"class-descriptions-boxable.csv\"\n",
    "    train_annotations_file = \"train-annotations-bbox.csv\"\n",
    "    \n",
    "    # Download the class descriptions if needed\n",
    "    if not os.path.exists(class_labels_file):\n",
    "        print(f\"Downloading {class_labels_file}...\")\n",
    "        os.system(f\"wget https://storage.googleapis.com/openimages/v5/class-descriptions-boxable.csv\")\n",
    "    \n",
    "    # Download the training annotations if needed\n",
    "    if not os.path.exists(train_annotations_file):\n",
    "        print(f\"Downloading {train_annotations_file}...\")\n",
    "        os.system(f\"wget https://storage.googleapis.com/openimages/2018_04/train/train-annotations-bbox.csv\")\n",
    "    \n",
    "    # Get class IDs for target classes\n",
    "    print(\"Finding class IDs for target vehicle classes...\")\n",
    "    class_id_map = {}\n",
    "    with open(class_labels_file, 'r') as f:\n",
    "        reader = csv.reader(f)\n",
    "        for row in reader:\n",
    "            class_name = row[1].lower()\n",
    "            for target_class in TARGET_CLASSES:\n",
    "                if target_class.lower() == class_name:\n",
    "                    class_id_map[row[0]] = target_class\n",
    "                    print(f\"Found {target_class} class ID: {row[0]}\")\n",
    "    \n",
    "    if not class_id_map:\n",
    "        print(\"Error: Could not find class IDs for target vehicle classes\")\n",
    "        return\n",
    "    \n",
    "    # Create a reverse mapping for easy lookup\n",
    "    target_class_ids = list(class_id_map.keys())\n",
    "    \n",
    "    # Track images by class\n",
    "    class_to_images = defaultdict(set)\n",
    "    images_with_multiple_classes = defaultdict(set)\n",
    "    \n",
    "    # Read the annotations file in chunks to handle its large size\n",
    "    print(\"Reading annotations and categorizing images by vehicle class...\")\n",
    "    chunk_size = 1000000\n",
    "    for chunk in tqdm.tqdm(pd.read_csv(train_annotations_file, chunksize=chunk_size)):\n",
    "        # Filter to only target class annotations\n",
    "        vehicle_annotations = chunk[chunk['LabelName'].isin(target_class_ids)]\n",
    "        \n",
    "        # Group by image and class\n",
    "        for _, row in vehicle_annotations.iterrows():\n",
    "            image_id = row['ImageID']\n",
    "            class_id = row['LabelName']\n",
    "            class_name = class_id_map[class_id]\n",
    "            class_to_images[class_name].add(image_id)\n",
    "            \n",
    "            # Also keep track of which classes each image has\n",
    "            images_with_multiple_classes[image_id].add(class_name)\n",
    "    \n",
    "    # Print statistics\n",
    "    for class_name, images in class_to_images.items():\n",
    "        print(f\"Found {len(images)} images with {class_name}\")\n",
    "    \n",
    "    # Select a balanced set of images for each class\n",
    "    selected_images = set()\n",
    "    random.seed(seed)\n",
    "    \n",
    "    for class_name in TARGET_CLASSES:\n",
    "        available_images = list(class_to_images.get(class_name, set()))\n",
    "        \n",
    "        if not available_images:\n",
    "            print(f\"Warning: No images found for class '{class_name}'\")\n",
    "            continue\n",
    "            \n",
    "        # Prioritize images that have only this class first\n",
    "        exclusive_images = [img_id for img_id in available_images \n",
    "                           if len(images_with_multiple_classes[img_id]) == 1]\n",
    "        \n",
    "        # If we don't have enough exclusive images, use images with multiple classes\n",
    "        if len(exclusive_images) >= images_per_class:\n",
    "            class_selection = random.sample(exclusive_images, images_per_class)\n",
    "        else:\n",
    "            # Take all exclusive images first\n",
    "            class_selection = exclusive_images\n",
    "            \n",
    "            # Then sample from images with multiple classes\n",
    "            multi_class_images = [img_id for img_id in available_images \n",
    "                                 if len(images_with_multiple_classes[img_id]) > 1]\n",
    "            \n",
    "            remaining_needed = images_per_class - len(class_selection)\n",
    "            if multi_class_images and remaining_needed > 0:\n",
    "                additional = random.sample(multi_class_images, \n",
    "                                          min(remaining_needed, len(multi_class_images)))\n",
    "                class_selection.extend(additional)\n",
    "        \n",
    "        selected_images.update(class_selection)\n",
    "        print(f\"Selected {len(class_selection)} images for {class_name}\")\n",
    "    \n",
    "    print(f\"Total selected images: {len(selected_images)}\")\n",
    "    \n",
    "    # Write selected image IDs to file\n",
    "    with open(output_file, 'w') as f:\n",
    "        for img_id in selected_images:\n",
    "            f.write(f\"train/{img_id}\\n\")\n",
    "    \n",
    "    print(f\"Image IDs saved to {output_file}\")\n",
    "    return selected_images\n",
    "\n",
    "###################################\n",
    "# Step 2: From the vehicle_images.txt file, download images to the data folder \n",
    "###################################\n",
    "def check_and_homogenize_one_image(image):\n",
    "    split, image_id = re.match(REGEX, image).groups()\n",
    "    yield split, image_id\n",
    "\n",
    "def check_and_homogenize_image_list(image_list):\n",
    "    for line_number, image in enumerate(image_list):\n",
    "        try:\n",
    "            yield from check_and_homogenize_one_image(image)\n",
    "        except (ValueError, AttributeError):\n",
    "            raise ValueError(\n",
    "                f'ERROR in line {line_number} of the image list. The following image '\n",
    "                f'string is not recognized: \"{image}\".')\n",
    "\n",
    "def read_image_list_file(image_list_file):\n",
    "    with open(image_list_file, 'r') as f:\n",
    "        for line in f:\n",
    "            yield line.strip().replace('.jpg', '')\n",
    "\n",
    "def download_one_image(bucket, split, image_id, download_folder):\n",
    "    try:\n",
    "        bucket.download_file(f'{split}/{image_id}.jpg',\n",
    "                            os.path.join(download_folder, f'{image_id}.jpg'))\n",
    "    except botocore.exceptions.ClientError as exception:\n",
    "        print(f'ERROR when downloading image `{split}/{image_id}`: {str(exception)}')\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def download_all_images(image_list_file, download_folder=\"data\", num_processes=14):\n",
    "    bucket = boto3.resource('s3', config=botocore.config.Config(signature_version=botocore.UNSIGNED)).Bucket(BUCKET_NAME)\n",
    "\n",
    "    if not os.path.exists(download_folder):\n",
    "        os.makedirs(download_folder)\n",
    "    try:\n",
    "        image_list = list(check_and_homogenize_image_list(read_image_list_file(image_list_file)))\n",
    "    except ValueError as exception:\n",
    "        sys.exit(exception)\n",
    "\n",
    "    progress_bar = tqdm.tqdm(total=len(image_list), desc='Downloading images', leave=True)\n",
    "    successful_downloads = []\n",
    "    \n",
    "    with futures.ThreadPoolExecutor(max_workers=num_processes) as executor:\n",
    "        all_futures = {\n",
    "            executor.submit(download_one_image, bucket, split, image_id, download_folder): (split, image_id)\n",
    "            for (split, image_id) in image_list\n",
    "        }\n",
    "        for future in futures.as_completed(all_futures):\n",
    "            result = future.result()\n",
    "            split, image_id = all_futures[future]\n",
    "            if result:\n",
    "                successful_downloads.append(f\"{split}/{image_id}\")\n",
    "            progress_bar.update(1)\n",
    "    \n",
    "    progress_bar.close()\n",
    "    \n",
    "    # Write successful downloads to a new file\n",
    "    success_file = image_list_file.replace(\".txt\", \"_successful.txt\")\n",
    "    with open(success_file, 'w') as f:\n",
    "        for image_path in successful_downloads:\n",
    "            f.write(f\"{image_path}\\n\")\n",
    "    \n",
    "    print(f\"Successfully downloaded {len(successful_downloads)} of {len(image_list)} images\")\n",
    "    print(f\"Successful downloads list saved to {success_file}\")\n",
    "    return success_file\n",
    "    \n",
    "###################################\n",
    "# Step 3: Extract vehicle labels from Open Images dataset -> export to vehicle_labels.csv\n",
    "###################################\n",
    "def extract_vehicle_labels_for_images(image_list_file, output_file=\"vehicle_labels.csv\"):\n",
    "    \"\"\"\n",
    "    Extract labels for target vehicle classes from images specified in image_list_file.\n",
    "    \n",
    "    Args:\n",
    "        image_list_file: File containing image IDs in format 'train/[IMAGE_ID]'\n",
    "        output_file: Path to save extracted labels \n",
    "    \"\"\"\n",
    "    print(\"Reading image IDs...\")\n",
    "    # Read image IDs from the file\n",
    "    image_ids = []\n",
    "    with open(image_list_file, 'r') as f:\n",
    "        for line in f:\n",
    "            # Extract just the ID part from \"train/ID\" format\n",
    "            parts = line.strip().split('/')\n",
    "            if len(parts) == 2:\n",
    "                image_ids.append(parts[1])\n",
    "\n",
    "    image_ids_set = set(image_ids)\n",
    "    print(f\"Found {len(image_ids_set)} unique image IDs\")\n",
    "\n",
    "    # Check if annotation files exist\n",
    "    class_desc_file = \"class-descriptions-boxable.csv\"  \n",
    "    bbox_file = \"train-annotations-bbox.csv\"\n",
    "\n",
    "    if not os.path.exists(class_desc_file):\n",
    "        print(f\"Please download the class descriptions file first:\")\n",
    "        print(\"wget https://storage.googleapis.com/openimages/v5/class-descriptions-boxable.csv\")\n",
    "        return\n",
    "    \n",
    "    if not os.path.exists(bbox_file):\n",
    "        print(f\"Please download the bounding box annotations file first:\")\n",
    "        print(\"wget https://storage.googleapis.com/openimages/2018_04/train/train-annotations-bbox.csv\")\n",
    "        return\n",
    "    \n",
    "    # Load class descriptions\n",
    "    print(\"Loading class descriptions...\")\n",
    "    class_descriptions = {}\n",
    "    vehicle_class_ids = []\n",
    "    \n",
    "    with open(class_desc_file, 'r') as f:\n",
    "        reader = csv.reader(f)\n",
    "        for row in reader:\n",
    "            class_descriptions[row[0]] = row[1]\n",
    "            # Filter for target vehicle classes\n",
    "            if row[1] in TARGET_CLASSES or row[1].lower() in [c.lower() for c in TARGET_CLASSES]:\n",
    "                vehicle_class_ids.append(row[0])\n",
    "\n",
    "    print(f\"Found {len(vehicle_class_ids)} target vehicle class IDs\")\n",
    "\n",
    "    # Process annotations in chunks to handle large file size\n",
    "    print(\"Extracting vehicle labels for your images...\")\n",
    "    extracted_labels = []\n",
    "    \n",
    "    # Process the file in chunks to save memory\n",
    "    chunk_size = 1000000\n",
    "    total_labels_found = 0\n",
    "\n",
    "    for chunk in tqdm.tqdm(pd.read_csv(bbox_file, chunksize=chunk_size)):\n",
    "        # Filter to only include our image IDs AND target vehicle classes\n",
    "        matching_annotations = chunk[(chunk['ImageID'].isin(image_ids_set)) & \n",
    "                                     (chunk['LabelName'].isin(vehicle_class_ids))].copy()\n",
    "        \n",
    "        if not matching_annotations.empty:\n",
    "            total_labels_found += len(matching_annotations)\n",
    "            # Add class name based on LabelName ID\n",
    "            matching_annotations['LabelName_Text'] = matching_annotations['LabelName'].apply(\n",
    "                lambda x: class_descriptions.get(x, 'Unknown'))\n",
    "            extracted_labels.append(matching_annotations)\n",
    "\n",
    "    if extracted_labels:\n",
    "        # Combine all chunks\n",
    "        all_labels = pd.concat(extracted_labels)\n",
    "        \n",
    "        # Check class balance\n",
    "        class_counts = all_labels['LabelName_Text'].value_counts()\n",
    "        print(\"\\nClass distribution in the dataset:\")\n",
    "        print(class_counts)\n",
    "        \n",
    "        # Calculate class weights for potential use in model training\n",
    "        total_samples = len(all_labels)\n",
    "        class_weights = {}\n",
    "        for class_name, count in class_counts.items():\n",
    "            class_weights[class_name] = total_samples / (len(class_counts) * count)\n",
    "        \n",
    "        print(\"\\nClass weights (for balanced training):\")\n",
    "        for class_name, weight in class_weights.items():\n",
    "            print(f\"{class_name}: {weight:.4f}\")\n",
    "        \n",
    "        # Save to CSV\n",
    "        all_labels.to_csv(output_file, index=False)\n",
    "        \n",
    "        print(f\"\\nFound {total_labels_found} vehicle annotations for {len(all_labels['ImageID'].unique())} images\")\n",
    "        print(f\"Labels saved to {output_file}\")\n",
    "        \n",
    "        # Return class counts for potential further processing\n",
    "        return class_counts\n",
    "    else:\n",
    "        print(\"No matching vehicle annotations found for your images\")\n",
    "        return None\n",
    "\n",
    "###################################\n",
    "# Run all steps in order\n",
    "###################################\n",
    "if __name__ == \"__main__\":\n",
    "    # Step 1: Find balanced set of images containing target classes\n",
    "    selected_images = find_balanced_vehicle_images(output_file=\"vehicle_images.txt\", images_per_class=1000, seed=1610)\n",
    "    \n",
    "    # Step 2: Download the selected images\n",
    "    successful_downloads_file = download_all_images(\"vehicle_images.txt\", download_folder=\"data\", num_processes=14)\n",
    "    \n",
    "    # Step 3: Extract labels for the downloaded images\n",
    "    class_counts = extract_vehicle_labels_for_images(successful_downloads_file, output_file=\"vehicle_labels.csv\")\n",
    "    \n",
    "    # Load and prepare final data\n",
    "    if os.path.exists(\"vehicle_labels.csv\"):\n",
    "        labels = pd.read_csv(\"vehicle_labels.csv\") \n",
    "        labels = labels[['ImageID', 'XMin', 'XMax', 'YMin', 'YMax', 'LabelName_Text']] \n",
    "        labels.to_csv(\"vehicle_labels.csv\", index=False)\n",
    "        \n",
    "        # Save basic dataset statistics\n",
    "        stats = {\n",
    "            \"total_images\": len(labels['ImageID'].unique()),\n",
    "            \"total_annotations\": len(labels),\n",
    "            \"class_distribution\": labels['LabelName_Text'].value_counts().to_dict()\n",
    "        }\n",
    "        \n",
    "        pd.DataFrame([stats]).to_json(\"dataset_stats.json\", orient=\"records\")\n",
    "        print(\"Final dataset statistics saved to dataset_stats.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "chuy·ªÉn ƒë·ªïi nh√£n t·ª´ file vehicle_labels.csv (ƒë·ªãnh d·∫°ng Open Images: ImageID, LabelName_Text, XMin, XMax, YMin, YMax) sang ƒë·ªãnh d·∫°ng YOLO (class_id x_center y_center width height)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# ƒê∆∞·ªùng d·∫´n\n",
    "data_dir = \"data\"\n",
    "labels_csv = \"vehicle_labels.csv\"\n",
    "labels_dir = \"/Users/admin/Car-detection-serving-model/open_images_project/labels\"\n",
    "os.makedirs(labels_dir, exist_ok=True)\n",
    "\n",
    "# √Ånh x·∫° l·ªõp\n",
    "class_mapping = {\n",
    "    'Car': 0,\n",
    "    'Taxi': 1,\n",
    "    'Truck': 2,\n",
    "    'Bus': 3\n",
    "}\n",
    "\n",
    "# ƒê·ªçc nh√£n\n",
    "labels = pd.read_csv(labels_csv)\n",
    "\n",
    "# Chuy·ªÉn ƒë·ªïi sang ƒë·ªãnh d·∫°ng YOLO\n",
    "for image_id in labels['ImageID'].unique():\n",
    "    image_labels = labels[labels['ImageID'] == image_id]\n",
    "    output_file = os.path.join(labels_dir, f\"{image_id}.txt\")\n",
    "    with open(output_file, 'w') as f:\n",
    "        for _, row in image_labels.iterrows():\n",
    "            class_name = row['LabelName_Text']\n",
    "            if class_name in class_mapping:\n",
    "                class_id = class_mapping[class_name]\n",
    "                x_min = row['XMin']\n",
    "                x_max = row['XMax']\n",
    "                y_min = row['YMin']\n",
    "                y_max = row['YMax']\n",
    "                x_center = (x_min + x_max) / 2\n",
    "                y_center = (y_min + y_max) / 2\n",
    "                width = x_max - x_min\n",
    "                height = y_max - y_min\n",
    "                f.write(f\"{class_id} {x_center} {y_center} {width} {height}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ph√¢n b·ªë l·ªõp trong dataset l·ªõn sau khi l√†m s·∫°ch:\n",
      "Train:\n",
      "Car: 5368 instances\n",
      "Taxi: 2912 instances\n",
      "Truck: 1565 instances\n",
      "Bus: 1735 instances\n",
      "S·ªë ·∫£nh train: 3600\n",
      "S·ªë ·∫£nh val: 400\n",
      "\n",
      "Kh√¥ng t√¨m th·∫•y class_id kh√¥ng h·ª£p l·ªá.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import glob\n",
    "\n",
    "# X√≥a th∆∞ m·ª•c c≈©\n",
    "os.system(\"rm -rf /Users/admin/Car-detection-serving-model/open_images_project/labels\")\n",
    "os.system(\"rm -rf /Users/admin/Car-detection-serving-model/open_images_project/dataset\")\n",
    "os.system(\"rm -rf /Users/admin/runs/detect/train_large\")  # ƒê·∫£m b·∫£o x√≥a l·∫ßn hu·∫•n luy·ªán tr∆∞·ªõc\n",
    "\n",
    "# ƒê∆∞·ªùng d·∫´n\n",
    "data_dir = \"data\"\n",
    "labels_csv = \"vehicle_labels.csv\"\n",
    "labels_dir = \"/Users/admin/Car-detection-serving-model/open_images_project/labels\"\n",
    "dataset_dir = \"/Users/admin/Car-detection-serving-model/open_images_project/dataset\"\n",
    "os.makedirs(labels_dir, exist_ok=True)\n",
    "os.makedirs(f\"{dataset_dir}/images/train\", exist_ok=True)\n",
    "os.makedirs(f\"{dataset_dir}/images/val\", exist_ok=True)\n",
    "os.makedirs(f\"{dataset_dir}/labels/train\", exist_ok=True)\n",
    "os.makedirs(f\"{dataset_dir}/labels/val\", exist_ok=True)\n",
    "\n",
    "# √Ånh x·∫° l·ªõp\n",
    "class_mapping = {\n",
    "    'Car': 0,\n",
    "    'Taxi': 1,\n",
    "    'Truck': 2,\n",
    "    'Bus': 3\n",
    "}\n",
    "\n",
    "# ƒê·ªçc nh√£n\n",
    "labels = pd.read_csv(labels_csv)\n",
    "\n",
    "# X√≥a duplicate labels\n",
    "labels = labels.drop_duplicates(subset=['ImageID', 'LabelName_Text', 'XMin', 'YMin', 'XMax', 'YMax'])\n",
    "\n",
    "# Chuy·ªÉn ƒë·ªïi sang ƒë·ªãnh d·∫°ng YOLO\n",
    "for image_id in labels['ImageID'].unique():\n",
    "    image_labels = labels[labels['ImageID'] == image_id]\n",
    "    output_file = os.path.join(labels_dir, f\"{image_id}.txt\")\n",
    "    with open(output_file, 'w') as f:\n",
    "        for _, row in image_labels.iterrows():\n",
    "            class_name = row['LabelName_Text']\n",
    "            if class_name in class_mapping:\n",
    "                class_id = class_mapping[class_name]\n",
    "                x_min = row['XMin']\n",
    "                x_max = row['XMax']\n",
    "                y_min = row['YMin']\n",
    "                y_max = row['YMax']\n",
    "                x_center = (x_min + x_max) / 2\n",
    "                y_center = (y_min + y_max) / 2\n",
    "                width = x_max - x_min\n",
    "                height = y_max - y_min\n",
    "                f.write(f\"{class_id} {x_center} {y_center} {width} {height}\\n\")\n",
    "\n",
    "# L·∫•y danh s√°ch ·∫£nh c√≥ nh√£n\n",
    "images_with_labels = []\n",
    "for img in os.listdir(data_dir):\n",
    "    if not img.endswith(\".jpg\"):\n",
    "        continue\n",
    "    lbl = os.path.join(labels_dir, img.replace(\".jpg\", \".txt\"))\n",
    "    if os.path.exists(lbl) and os.path.getsize(lbl) > 0:  # Ch·ªâ l·∫•y ·∫£nh c√≥ nh√£n\n",
    "        images_with_labels.append(img)\n",
    "\n",
    "random.seed(1610)\n",
    "\n",
    "# Chia train/val (90% train, 10% val)\n",
    "train_imgs = random.sample(images_with_labels, int(0.9 * len(images_with_labels)))\n",
    "val_imgs = [img for img in images_with_labels if img not in train_imgs]\n",
    "\n",
    "# Sao ch√©p ·∫£nh v√† nh√£n v√†o th∆∞ m·ª•c train\n",
    "for img in train_imgs:\n",
    "    shutil.copy(os.path.join(data_dir, img), f\"{dataset_dir}/images/train/{img}\")\n",
    "    lbl = img.replace(\".jpg\", \".txt\")\n",
    "    shutil.copy(os.path.join(labels_dir, lbl), f\"{dataset_dir}/labels/train/{lbl}\")\n",
    "\n",
    "# Sao ch√©p ·∫£nh v√† nh√£n v√†o th∆∞ m·ª•c val\n",
    "for img in val_imgs:\n",
    "    shutil.copy(os.path.join(data_dir, img), f\"{dataset_dir}/images/val/{img}\")\n",
    "    lbl = img.replace(\".jpg\", \".txt\")\n",
    "    shutil.copy(os.path.join(labels_dir, lbl), f\"{dataset_dir}/labels/val/{lbl}\")\n",
    "\n",
    "# Ki·ªÉm tra ph√¢n b·ªë l·ªõp\n",
    "class_counts = {i: 0 for i in range(len(class_mapping))}\n",
    "invalid_files = []\n",
    "for label_file in glob.glob(f\"{dataset_dir}/labels/*/*.txt\"):\n",
    "    with open(label_file, \"r\") as f:\n",
    "        for line in f:\n",
    "            if line.strip():\n",
    "                class_id = int(line.split()[0])\n",
    "                if class_id in class_counts:\n",
    "                    class_counts[class_id] += 1\n",
    "                else:\n",
    "                    invalid_files.append((label_file, class_id))\n",
    "\n",
    "class_names = list(class_mapping.keys())\n",
    "print(\"Ph√¢n b·ªë l·ªõp trong dataset l·ªõn sau khi l√†m s·∫°ch:\")\n",
    "print(\"Train:\")\n",
    "for i in range(len(class_names)):\n",
    "    print(f\"{class_names[i]}: {class_counts[i]} instances\")\n",
    "print(f\"S·ªë ·∫£nh train: {len(train_imgs)}\")\n",
    "print(f\"S·ªë ·∫£nh val: {len(val_imgs)}\")\n",
    "\n",
    "if invalid_files:\n",
    "    print(\"\\nC√°c file ch·ª©a class_id kh√¥ng h·ª£p l·ªá:\")\n",
    "    for file, class_id in invalid_files:\n",
    "        print(f\"File: {file}, class_id: {class_id}\")\n",
    "else:\n",
    "    print(\"\\nKh√¥ng t√¨m th·∫•y class_id kh√¥ng h·ª£p l·ªá.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ƒê√£ t·∫°o data.yaml v·ªõi 4 l·ªõp v√† augmentation\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "dataset_dir = \"/Users/admin/Car-detection-serving-model/open_images_project/dataset\"\n",
    "data_yaml_content = f\"\"\"train: {dataset_dir}/images/train\n",
    "val: {dataset_dir}/images/val\n",
    "nc: 4\n",
    "names: ['Car', 'Taxi', 'Truck', 'Bus']\n",
    "# Data augmentation\n",
    "hsv_h: 0.015  # Hue\n",
    "hsv_s: 0.7    # Saturation\n",
    "hsv_v: 0.4    # Value\n",
    "degrees: 15.0  # Rotation\n",
    "translate: 0.1  # Translation\n",
    "scale: 0.5     # Scaling\n",
    "shear: 0.0     # Shear\n",
    "flipud: 0.5    # Flip up-down\n",
    "fliplr: 0.5    # Flip left-right\n",
    "mosaic: 1.0    # Mosaic\n",
    "mixup: 0.0     # Mixup\n",
    "\"\"\"\n",
    "with open(f\"{dataset_dir}/data.yaml\", \"w\") as f:\n",
    "    f.write(data_yaml_content)\n",
    "print(\"ƒê√£ t·∫°o data.yaml v·ªõi 4 l·ªõp v√† augmentation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hu·∫•n luy·ªán l·∫ßn ƒë·∫ßu v·ªõi m√¥ h√¨nh pretrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ultralytics in ./yolo_env_new/lib/python3.11/site-packages (8.3.115)\n",
      "Requirement already satisfied: numpy<=2.1.1,>=1.23.0 in ./yolo_env_new/lib/python3.11/site-packages (from ultralytics) (1.26.4)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in ./yolo_env_new/lib/python3.11/site-packages (from ultralytics) (3.10.1)\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in ./yolo_env_new/lib/python3.11/site-packages (from ultralytics) (4.11.0.86)\n",
      "Requirement already satisfied: pillow>=7.1.2 in ./yolo_env_new/lib/python3.11/site-packages (from ultralytics) (11.2.1)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in ./yolo_env_new/lib/python3.11/site-packages (from ultralytics) (6.0.2)\n",
      "Requirement already satisfied: requests>=2.23.0 in ./yolo_env_new/lib/python3.11/site-packages (from ultralytics) (2.32.3)\n",
      "Requirement already satisfied: scipy>=1.4.1 in ./yolo_env_new/lib/python3.11/site-packages (from ultralytics) (1.15.2)\n",
      "Requirement already satisfied: torch>=1.8.0 in ./yolo_env_new/lib/python3.11/site-packages (from ultralytics) (2.2.2)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in ./yolo_env_new/lib/python3.11/site-packages (from ultralytics) (0.17.2)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in ./yolo_env_new/lib/python3.11/site-packages (from ultralytics) (4.67.1)\n",
      "Requirement already satisfied: psutil in ./yolo_env_new/lib/python3.11/site-packages (from ultralytics) (7.0.0)\n",
      "Requirement already satisfied: py-cpuinfo in ./yolo_env_new/lib/python3.11/site-packages (from ultralytics) (9.0.0)\n",
      "Requirement already satisfied: pandas>=1.1.4 in ./yolo_env_new/lib/python3.11/site-packages (from ultralytics) (2.2.3)\n",
      "Requirement already satisfied: seaborn>=0.11.0 in ./yolo_env_new/lib/python3.11/site-packages (from ultralytics) (0.13.2)\n",
      "Requirement already satisfied: ultralytics-thop>=2.0.0 in ./yolo_env_new/lib/python3.11/site-packages (from ultralytics) (2.0.14)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./yolo_env_new/lib/python3.11/site-packages (from matplotlib>=3.3.0->ultralytics) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in ./yolo_env_new/lib/python3.11/site-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./yolo_env_new/lib/python3.11/site-packages (from matplotlib>=3.3.0->ultralytics) (4.57.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in ./yolo_env_new/lib/python3.11/site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in ./yolo_env_new/lib/python3.11/site-packages (from matplotlib>=3.3.0->ultralytics) (24.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in ./yolo_env_new/lib/python3.11/site-packages (from matplotlib>=3.3.0->ultralytics) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in ./yolo_env_new/lib/python3.11/site-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./yolo_env_new/lib/python3.11/site-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./yolo_env_new/lib/python3.11/site-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./yolo_env_new/lib/python3.11/site-packages (from requests>=2.23.0->ultralytics) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./yolo_env_new/lib/python3.11/site-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./yolo_env_new/lib/python3.11/site-packages (from requests>=2.23.0->ultralytics) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./yolo_env_new/lib/python3.11/site-packages (from requests>=2.23.0->ultralytics) (2025.1.31)\n",
      "Requirement already satisfied: filelock in ./yolo_env_new/lib/python3.11/site-packages (from torch>=1.8.0->ultralytics) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in ./yolo_env_new/lib/python3.11/site-packages (from torch>=1.8.0->ultralytics) (4.13.2)\n",
      "Requirement already satisfied: sympy in ./yolo_env_new/lib/python3.11/site-packages (from torch>=1.8.0->ultralytics) (1.13.3)\n",
      "Requirement already satisfied: networkx in ./yolo_env_new/lib/python3.11/site-packages (from torch>=1.8.0->ultralytics) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in ./yolo_env_new/lib/python3.11/site-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
      "Requirement already satisfied: fsspec in ./yolo_env_new/lib/python3.11/site-packages (from torch>=1.8.0->ultralytics) (2025.3.2)\n",
      "Requirement already satisfied: six>=1.5 in ./yolo_env_new/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./yolo_env_new/lib/python3.11/site-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./yolo_env_new/lib/python3.11/site-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "New https://pypi.org/project/ultralytics/8.3.119 available üòÉ Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.115 üöÄ Python-3.11.4 torch-2.2.2 CPU (Intel Core(TM) i7-8559U 2.70GHz)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolo11n.pt, data=/Users/admin/Car-detection-serving-model/open_images_project/dataset/data.yaml, epochs=30, time=None, patience=100, batch=16, imgsz=416, save=True, save_period=-1, cache=False, device=cpu, workers=8, project=None, name=train_large_new, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, cfg=None, tracker=botsort.yaml, save_dir=/Users/admin/runs/detect/train_large_new\n",
      "Overriding model.yaml nc=80 with nc=4\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n",
      "  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      "  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
      "  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      "  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    111296  ultralytics.nn.modules.block.C3k2            [384, 128, 1, False]          \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1     32096  ultralytics.nn.modules.block.C3k2            [256, 64, 1, False]           \n",
      " 17                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1     86720  ultralytics.nn.modules.block.C3k2            [192, 128, 1, False]          \n",
      " 20                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1    378880  ultralytics.nn.modules.block.C3k2            [384, 256, 1, True]           \n",
      " 23        [16, 19, 22]  1    431452  ultralytics.nn.modules.head.Detect           [4, [64, 128, 256]]           \n",
      "YOLO11n summary: 181 layers, 2,590,620 parameters, 2,590,604 gradients, 6.4 GFLOPs\n",
      "\n",
      "Transferred 448/499 items from pretrained weights\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 479.3¬±227.5 MB/s, size: 335.8 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /Users/admin/Car-detection-serving-model/open_images_project/dataset/labels/train... 3600 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3600/3600 [00:02<00:00, 1251.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /Users/admin/Car-detection-serving-model/open_images_project/dataset/labels/train.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 997.9¬±233.6 MB/s, size: 237.5 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/admin/Car-detection-serving-model/open_images_project/dataset/labels/val... 400 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 400/400 [00:00<00:00, 1312.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /Users/admin/Car-detection-serving-model/open_images_project/dataset/labels/val.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to /Users/admin/runs/detect/train_large_new/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.00125, momentum=0.9) with parameter groups 81 weight(decay=0.0), 88 weight(decay=0.0005), 87 bias(decay=0.0)\n",
      "Image sizes 416 train, 416 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1m/Users/admin/runs/detect/train_large_new\u001b[0m\n",
      "Starting training for 30 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/30         0G      1.243      2.379      1.277         81        416: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 225/225 [16:10<00:00,  4.31s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:35<00:00,  2.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        400       1203       0.42       0.46      0.417      0.269\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/30         0G      1.302      1.842      1.304         80        416: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 225/225 [15:12<00:00,  4.05s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:33<00:00,  2.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        400       1203      0.479      0.412        0.4      0.244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/30         0G      1.319      1.784      1.319         65        416: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 225/225 [15:13<00:00,  4.06s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:32<00:00,  2.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        400       1203      0.541      0.439      0.456      0.282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/30         0G      1.312      1.712      1.306        113        416: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 225/225 [14:37<00:00,  3.90s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:33<00:00,  2.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        400       1203      0.554      0.472      0.501      0.321\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/30         0G      1.277      1.613      1.287         87        416: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 225/225 [14:52<00:00,  3.97s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:33<00:00,  2.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        400       1203      0.621      0.498       0.53      0.346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/30         0G      1.249      1.569      1.276        120        416: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 225/225 [14:58<00:00,  3.99s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:31<00:00,  2.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        400       1203      0.586      0.469      0.503      0.322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/30         0G      1.239       1.53       1.26         89        416: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 225/225 [15:04<00:00,  4.02s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:33<00:00,  2.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        400       1203      0.631      0.493      0.538      0.353\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/30         0G        1.2      1.482      1.244         95        416: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 225/225 [14:38<00:00,  3.90s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:34<00:00,  2.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        400       1203      0.584        0.5      0.544      0.363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/30         0G      1.193      1.437       1.24         76        416: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 225/225 [14:42<00:00,  3.92s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:32<00:00,  2.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        400       1203      0.698      0.565      0.626      0.426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/30         0G      1.182      1.397       1.23         98        416: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 225/225 [14:56<00:00,  3.99s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:35<00:00,  2.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        400       1203      0.658      0.565      0.613      0.419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      11/30         0G      1.165      1.397      1.229        104        416: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 225/225 [14:52<00:00,  3.97s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:33<00:00,  2.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        400       1203       0.62      0.582      0.627      0.434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      12/30         0G      1.128      1.328      1.207         94        416: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 225/225 [14:44<00:00,  3.93s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:33<00:00,  2.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        400       1203       0.66      0.575      0.641      0.441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      13/30         0G       1.14      1.327      1.211         92        416: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 225/225 [14:57<00:00,  3.99s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:29<00:00,  2.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        400       1203      0.676      0.558      0.638      0.439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      14/30         0G      1.112      1.282      1.194        104        416: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 225/225 [13:45<00:00,  3.67s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:30<00:00,  2.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        400       1203      0.677      0.555      0.625      0.433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      15/30         0G      1.111      1.264      1.189         86        416: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 225/225 [13:51<00:00,  3.70s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:33<00:00,  2.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        400       1203      0.702      0.569      0.646      0.457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      16/30         0G      1.085       1.24      1.187         86        416: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 225/225 [13:12<00:00,  3.52s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:29<00:00,  2.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        400       1203      0.702      0.607      0.667      0.471\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      17/30         0G      1.083      1.227      1.183         94        416: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 225/225 [13:46<00:00,  3.67s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:31<00:00,  2.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        400       1203       0.72      0.586      0.661      0.465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      18/30         0G      1.078      1.206      1.179         64        416: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 225/225 [13:11<00:00,  3.52s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:29<00:00,  2.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        400       1203      0.719      0.601      0.673      0.477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      19/30         0G      1.056      1.176      1.166         90        416: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 225/225 [13:16<00:00,  3.54s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:28<00:00,  2.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        400       1203      0.713      0.582      0.669      0.475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      20/30         0G      1.063      1.194      1.168         88        416: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 225/225 [14:06<00:00,  3.76s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:31<00:00,  2.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        400       1203      0.731      0.594      0.682      0.483\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      21/30         0G      1.061      1.134      1.154         62        416: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 225/225 [13:48<00:00,  3.68s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:30<00:00,  2.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        400       1203       0.72      0.571      0.654      0.462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      22/30         0G      1.039      1.074      1.149         62        416: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 225/225 [13:35<00:00,  3.63s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:30<00:00,  2.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        400       1203      0.739      0.597      0.682      0.483\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      23/30         0G      1.022      1.044      1.136         43        416: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 225/225 [13:39<00:00,  3.64s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:30<00:00,  2.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        400       1203      0.741      0.597      0.687      0.489\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      24/30         0G      1.013      1.018      1.128         31        416: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 225/225 [13:43<00:00,  3.66s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:35<00:00,  2.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        400       1203       0.74       0.61      0.691      0.495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      25/30         0G      1.001     0.9919      1.124         38        416: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 225/225 [14:59<00:00,  4.00s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:33<00:00,  2.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        400       1203      0.733      0.634      0.705      0.505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      26/30         0G     0.9954     0.9774      1.115         36        416: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 225/225 [14:31<00:00,  3.87s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:31<00:00,  2.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        400       1203      0.712      0.626       0.69      0.499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      27/30         0G     0.9817     0.9485      1.108         27        416: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 225/225 [14:35<00:00,  3.89s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:32<00:00,  2.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        400       1203      0.709      0.642      0.705      0.508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      28/30         0G     0.9669     0.9177      1.104         44        416: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 225/225 [14:37<00:00,  3.90s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:33<00:00,  2.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        400       1203      0.732      0.622        0.7      0.504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      29/30         0G     0.9599       0.91      1.096         38        416: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 225/225 [14:57<00:00,  3.99s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:32<00:00,  2.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        400       1203      0.743      0.625      0.711      0.514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      30/30         0G     0.9466     0.8966      1.097         44        416: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 225/225 [14:34<00:00,  3.89s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:33<00:00,  2.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        400       1203       0.79      0.594      0.711      0.515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "30 epochs completed in 7.494 hours.\n",
      "Optimizer stripped from /Users/admin/runs/detect/train_large_new/weights/last.pt, 5.4MB\n",
      "Optimizer stripped from /Users/admin/runs/detect/train_large_new/weights/best.pt, 5.4MB\n",
      "\n",
      "Validating /Users/admin/runs/detect/train_large_new/weights/best.pt...\n",
      "Ultralytics 8.3.115 üöÄ Python-3.11.4 torch-2.2.2 CPU (Intel Core(TM) i7-8559U 2.70GHz)\n",
      "YOLO11n summary (fused): 100 layers, 2,582,932 parameters, 0 gradients, 6.3 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:29<00:00,  2.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        400       1203      0.789      0.594      0.711      0.515\n",
      "                   Car        167        592      0.727      0.427       0.57      0.377\n",
      "                  Taxi        104        298      0.806      0.529      0.685      0.435\n",
      "                 Truck        103        136      0.829      0.713      0.809      0.618\n",
      "                   Bus        101        177      0.793      0.706      0.779      0.632\n",
      "Speed: 1.3ms preprocess, 51.2ms inference, 0.0ms loss, 1.1ms postprocess per image\n",
      "Results saved to \u001b[1m/Users/admin/runs/detect/train_large_new\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install ultralytics\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# T·∫£i m√¥ h√¨nh pretrained\n",
    "model = YOLO(\"yolo11n.pt\")\n",
    "\n",
    "# Hu·∫•n luy·ªán\n",
    "results = model.train(\n",
    "    data=\"/Users/admin/Car-detection-serving-model/open_images_project/dataset/data.yaml\",\n",
    "    epochs=30,  # 30 epochs\n",
    "    imgsz=416,  # TƒÉng l√™n 416\n",
    "    batch=16,   # Ph√π h·ª£p CPU\n",
    "    device=\"cpu\",  # Ch·∫°y tr√™n CPU\n",
    "    name=\"train_large_new\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hu·∫•n luy·ªán ti·∫øp t·ª•c t·ª´ last.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.3.119 available üòÉ Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.115 üöÄ Python-3.11.4 torch-2.2.2 CPU (Intel Core(TM) i7-8559U 2.70GHz)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=/Users/admin/runs/detect/train_large_new/weights/last.pt, data=/Users/admin/Car-detection-serving-model/open_images_project/dataset/data.yaml, epochs=10, time=None, patience=100, batch=16, imgsz=416, save=True, save_period=-1, cache=False, device=cpu, workers=8, project=None, name=train_large_new_extended, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, cfg=None, tracker=botsort.yaml, save_dir=/Users/admin/runs/detect/train_large_new_extended\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n",
      "  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      "  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
      "  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      "  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    111296  ultralytics.nn.modules.block.C3k2            [384, 128, 1, False]          \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1     32096  ultralytics.nn.modules.block.C3k2            [256, 64, 1, False]           \n",
      " 17                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1     86720  ultralytics.nn.modules.block.C3k2            [192, 128, 1, False]          \n",
      " 20                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1    378880  ultralytics.nn.modules.block.C3k2            [384, 256, 1, True]           \n",
      " 23        [16, 19, 22]  1    431452  ultralytics.nn.modules.head.Detect           [4, [64, 128, 256]]           \n",
      "YOLO11n summary: 181 layers, 2,590,620 parameters, 2,590,604 gradients, 6.4 GFLOPs\n",
      "\n",
      "Transferred 499/499 items from pretrained weights\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 336.1¬±111.6 MB/s, size: 335.8 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /Users/admin/Car-detection-serving-model/open_images_project/dataset/labels/train.cache... 3600 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3600/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.1¬±0.0 ms, read: 178.6¬±168.0 MB/s, size: 237.5 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/admin/Car-detection-serving-model/open_images_project/dataset/labels/val.cache... 400 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 400/400 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to /Users/admin/runs/detect/train_large_new_extended/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.00125, momentum=0.9) with parameter groups 81 weight(decay=0.0), 88 weight(decay=0.0005), 87 bias(decay=0.0)\n",
      "Image sizes 416 train, 416 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1m/Users/admin/runs/detect/train_large_new_extended\u001b[0m\n",
      "Starting training for 10 epochs...\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/10         0G     0.9781     0.9397      1.111         40        416: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 225/225 [13:34<00:00,  3.62s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:30<00:00,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        400       1203      0.742      0.584      0.683      0.482\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/10         0G      1.063      1.087      1.153         54        416: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 225/225 [13:50<00:00,  3.69s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:32<00:00,  2.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        400       1203      0.662      0.551       0.62      0.434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/10         0G      1.088      1.144      1.177         38        416: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 225/225 [13:55<00:00,  3.71s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:30<00:00,  2.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        400       1203        0.7      0.531      0.614      0.426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/10         0G      1.124      1.163      1.193         48        416: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 225/225 [13:51<00:00,  3.70s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:29<00:00,  2.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        400       1203       0.67      0.576      0.632      0.432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/10         0G      1.091      1.131      1.181         67        416: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 225/225 [13:44<00:00,  3.66s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:30<00:00,  2.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        400       1203      0.708      0.553      0.624      0.429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/10         0G       1.06      1.074      1.163         37        416: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 225/225 [13:39<00:00,  3.64s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:30<00:00,  2.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        400       1203       0.69      0.632      0.674      0.476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/10         0G      1.033      1.037      1.148         29        416: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 225/225 [13:46<00:00,  3.68s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:30<00:00,  2.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        400       1203      0.723      0.603      0.689      0.486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/10         0G       1.01     0.9765      1.129         56        416: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 225/225 [13:36<00:00,  3.63s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:29<00:00,  2.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        400       1203      0.735      0.591      0.672      0.483\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/10         0G     0.9844     0.9472      1.118         41        416: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 225/225 [14:14<00:00,  3.80s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:29<00:00,  2.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        400       1203      0.749      0.604      0.686      0.496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/10         0G     0.9698     0.9064        1.1         39        416: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 225/225 [13:47<00:00,  3.68s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:30<00:00,  2.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        400       1203      0.758       0.63      0.705       0.51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "10 epochs completed in 2.386 hours.\n",
      "Optimizer stripped from /Users/admin/runs/detect/train_large_new_extended/weights/last.pt, 5.4MB\n",
      "Optimizer stripped from /Users/admin/runs/detect/train_large_new_extended/weights/best.pt, 5.4MB\n",
      "\n",
      "Validating /Users/admin/runs/detect/train_large_new_extended/weights/best.pt...\n",
      "Ultralytics 8.3.115 üöÄ Python-3.11.4 torch-2.2.2 CPU (Intel Core(TM) i7-8559U 2.70GHz)\n",
      "YOLO11n summary (fused): 100 layers, 2,582,932 parameters, 0 gradients, 6.3 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:26<00:00,  2.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        400       1203      0.759       0.63      0.705      0.511\n",
      "                   Car        167        592      0.692      0.478      0.563      0.373\n",
      "                  Taxi        104        298       0.77      0.594      0.683      0.432\n",
      "                 Truck        103        136      0.772      0.747      0.809      0.627\n",
      "                   Bus        101        177      0.801      0.701      0.764       0.61\n",
      "Speed: 1.3ms preprocess, 44.9ms inference, 0.0ms loss, 1.1ms postprocess per image\n",
      "Results saved to \u001b[1m/Users/admin/runs/detect/train_large_new_extended\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# T·∫£i m√¥ h√¨nh ƒë√£ hu·∫•n luy·ªán\n",
    "model = YOLO(\"/Users/admin/runs/detect/train_large_new/weights/last.pt\")\n",
    "\n",
    "# Hu·∫•n luy·ªán ti·∫øp\n",
    "results = model.train(\n",
    "    data=\"/Users/admin/Car-detection-serving-model/open_images_project/dataset/data.yaml\",\n",
    "    epochs=10,  # Th√™m 10 epochs\n",
    "    imgsz=416,\n",
    "    batch=16,\n",
    "    device=\"cpu\",\n",
    "    name=\"train_large_new_extended\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hu·∫•n luy·ªán ti·∫øp v·ªõi learning rate th·∫•p h∆°n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.3.119 available üòÉ Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.115 üöÄ Python-3.11.4 torch-2.2.2 CPU (Intel Core(TM) i7-8559U 2.70GHz)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=/Users/admin/runs/detect/train_large_new_extended/weights/last.pt, data=/Users/admin/Car-detection-serving-model/open_images_project/dataset/data.yaml, epochs=10, time=None, patience=100, batch=16, imgsz=416, save=True, save_period=-1, cache=False, device=cpu, workers=8, project=None, name=train_large_new_extended_2, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.0005, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, cfg=None, tracker=botsort.yaml, save_dir=/Users/admin/runs/detect/train_large_new_extended_2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n",
      "  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      "  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
      "  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      "  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    111296  ultralytics.nn.modules.block.C3k2            [384, 128, 1, False]          \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1     32096  ultralytics.nn.modules.block.C3k2            [256, 64, 1, False]           \n",
      " 17                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1     86720  ultralytics.nn.modules.block.C3k2            [192, 128, 1, False]          \n",
      " 20                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1    378880  ultralytics.nn.modules.block.C3k2            [384, 256, 1, True]           \n",
      " 23        [16, 19, 22]  1    431452  ultralytics.nn.modules.head.Detect           [4, [64, 128, 256]]           \n",
      "YOLO11n summary: 181 layers, 2,590,620 parameters, 2,590,604 gradients, 6.4 GFLOPs\n",
      "\n",
      "Transferred 499/499 items from pretrained weights\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ‚úÖ (ping: 0.2¬±0.3 ms, read: 360.8¬±132.6 MB/s, size: 335.8 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /Users/admin/Car-detection-serving-model/open_images_project/dataset/labels/train.cache... 3600 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3600/3600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 387.4¬±160.6 MB/s, size: 237.5 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/admin/Car-detection-serving-model/open_images_project/dataset/labels/val.cache... 400 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 400/400 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to /Users/admin/runs/detect/train_large_new_extended_2/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.0005' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.00125, momentum=0.9) with parameter groups 81 weight(decay=0.0), 88 weight(decay=0.0005), 87 bias(decay=0.0)\n",
      "Image sizes 416 train, 416 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1m/Users/admin/runs/detect/train_large_new_extended_2\u001b[0m\n",
      "Starting training for 10 epochs...\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/10         0G     0.9493      0.885      1.092         40        416: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 225/225 [13:53<00:00,  3.71s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:33<00:00,  2.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        400       1203      0.729       0.59       0.67      0.475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/10         0G     0.9921     0.9696      1.116         54        416: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 225/225 [13:47<00:00,  3.68s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:31<00:00,  2.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        400       1203      0.753      0.537      0.636      0.442\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/10         0G      1.015      1.006      1.131         38        416: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 225/225 [13:41<00:00,  3.65s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:31<00:00,  2.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        400       1203      0.651      0.585      0.632      0.436\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/10         0G      1.047      1.056      1.145         48        416: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 225/225 [13:54<00:00,  3.71s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:30<00:00,  2.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        400       1203      0.627      0.559      0.588      0.398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/10         0G      1.028      1.028       1.14         67        416: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 225/225 [13:54<00:00,  3.71s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:32<00:00,  2.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        400       1203      0.724       0.58      0.659      0.462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/10         0G      1.001     0.9671      1.121         37        416: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 225/225 [14:29<00:00,  3.86s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:32<00:00,  2.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        400       1203      0.703      0.627      0.684      0.476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/10         0G     0.9802     0.9318      1.115         29        416: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 225/225 [14:29<00:00,  3.86s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:32<00:00,  2.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        400       1203      0.702      0.579      0.652      0.461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/10         0G     0.9711     0.8996      1.104         56        416: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 225/225 [14:45<00:00,  3.93s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:34<00:00,  2.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        400       1203      0.751      0.603      0.687      0.492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/10         0G     0.9443     0.8676      1.093         41        416: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 225/225 [15:04<00:00,  4.02s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:34<00:00,  2.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        400       1203      0.772      0.598      0.689      0.493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/10         0G     0.9433     0.8428      1.084         39        416: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 225/225 [14:57<00:00,  3.99s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:33<00:00,  2.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        400       1203       0.73      0.627      0.696      0.501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "10 epochs completed in 2.475 hours.\n",
      "Optimizer stripped from /Users/admin/runs/detect/train_large_new_extended_2/weights/last.pt, 5.4MB\n",
      "Optimizer stripped from /Users/admin/runs/detect/train_large_new_extended_2/weights/best.pt, 5.4MB\n",
      "\n",
      "Validating /Users/admin/runs/detect/train_large_new_extended_2/weights/best.pt...\n",
      "Ultralytics 8.3.115 üöÄ Python-3.11.4 torch-2.2.2 CPU (Intel Core(TM) i7-8559U 2.70GHz)\n",
      "YOLO11n summary (fused): 100 layers, 2,582,932 parameters, 0 gradients, 6.3 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:30<00:00,  2.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        400       1203      0.728      0.631      0.696        0.5\n",
      "                   Car        167        592      0.672      0.495       0.56      0.371\n",
      "                  Taxi        104        298      0.741       0.57      0.671      0.425\n",
      "                 Truck        103        136      0.761      0.743      0.797      0.598\n",
      "                   Bus        101        177      0.738      0.717      0.755      0.607\n",
      "Speed: 1.3ms preprocess, 51.8ms inference, 0.0ms loss, 1.0ms postprocess per image\n",
      "Results saved to \u001b[1m/Users/admin/runs/detect/train_large_new_extended_2\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# T·∫£i m√¥ h√¨nh ƒë√£ hu·∫•n luy·ªán\n",
    "model = YOLO(\"/Users/admin/runs/detect/train_large_new_extended/weights/last.pt\")\n",
    "\n",
    "# Hu·∫•n luy·ªán ti·∫øp v·ªõi learning rate th·∫•p h∆°n\n",
    "results = model.train(\n",
    "    data=\"/Users/admin/Car-detection-serving-model/open_images_project/dataset/data.yaml\",\n",
    "    epochs=10,  # Th√™m 10 epochs\n",
    "    imgsz=416,\n",
    "    batch=16,\n",
    "    device=\"cpu\",\n",
    "    lr0=0.0005,  # Gi·∫£m learning rate\n",
    "    name=\"train_large_new_extended_2\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C·∫≠p nh·∫≠t data.yaml v·ªõi augmentation m·ªõi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ƒê√£ c·∫≠p nh·∫≠t data.yaml v·ªõi degrees=15.0\n"
     ]
    }
   ],
   "source": [
    "dataset_dir = \"/Users/admin/Car-detection-serving-model/open_images_project/dataset\"\n",
    "data_yaml_content = f\"\"\"train: {dataset_dir}/images/train\n",
    "val: {dataset_dir}/images/val\n",
    "nc: 4\n",
    "names: ['Car', 'Taxi', 'Truck', 'Bus']\n",
    "# Data augmentation\n",
    "hsv_h: 0.015\n",
    "hsv_s: 0.7\n",
    "hsv_v: 0.4\n",
    "degrees: 15.0  # TƒÉng t·ª´ 10.0 l√™n 15.0\n",
    "translate: 0.1\n",
    "scale: 0.5\n",
    "shear: 0.0\n",
    "flipud: 0.5\n",
    "fliplr: 0.5\n",
    "mosaic: 1.0\n",
    "mixup: 0.0\n",
    "\"\"\"\n",
    "with open(f\"{dataset_dir}/data.yaml\", \"w\") as f:\n",
    "    f.write(data_yaml_content)\n",
    "print(\"ƒê√£ c·∫≠p nh·∫≠t data.yaml v·ªõi degrees=15.0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hu·∫•n luy·ªán l·∫ßn cu·ªëi v·ªõi c·∫•u h√¨nh m·ªõi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.3.120 available üòÉ Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.115 üöÄ Python-3.11.4 torch-2.2.2 CPU (Intel Core(TM) i7-8559U 2.70GHz)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=/Users/admin/runs/detect/train_large_new_extended_2/weights/last.pt, data=/Users/admin/Car-detection-serving-model/open_images_project/dataset/data.yaml, epochs=10, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=cpu, workers=8, project=None, name=train_large_new_final, exist_ok=False, pretrained=True, optimizer=AdamW, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.0005, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, cfg=None, tracker=botsort.yaml, save_dir=/Users/admin/runs/detect/train_large_new_final\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n",
      "  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      "  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
      "  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      "  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    111296  ultralytics.nn.modules.block.C3k2            [384, 128, 1, False]          \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1     32096  ultralytics.nn.modules.block.C3k2            [256, 64, 1, False]           \n",
      " 17                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1     86720  ultralytics.nn.modules.block.C3k2            [192, 128, 1, False]          \n",
      " 20                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1    378880  ultralytics.nn.modules.block.C3k2            [384, 256, 1, True]           \n",
      " 23        [16, 19, 22]  1    431452  ultralytics.nn.modules.head.Detect           [4, [64, 128, 256]]           \n",
      "YOLO11n summary: 181 layers, 2,590,620 parameters, 2,590,604 gradients, 6.4 GFLOPs\n",
      "\n",
      "Transferred 499/499 items from pretrained weights\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ‚úÖ (ping: 0.1¬±0.2 ms, read: 426.5¬±234.1 MB/s, size: 335.8 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /Users/admin/Car-detection-serving-model/open_images_project/dataset/labels/train.cache... 3600 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3600/3600 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.4¬±0.2 ms, read: 322.8¬±192.0 MB/s, size: 237.5 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/admin/Car-detection-serving-model/open_images_project/dataset/labels/val.cache... 400 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 400/400 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to /Users/admin/runs/detect/train_large_new_final/labels.jpg... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.0005, momentum=0.937) with parameter groups 81 weight(decay=0.0), 88 weight(decay=0.0005), 87 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1m/Users/admin/runs/detect/train_large_new_final\u001b[0m\n",
      "Starting training for 10 epochs...\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/10         0G      1.204      1.226      1.419         40        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 225/225 [31:23<00:00,  8.37s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:56<00:00,  4.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        400       1203      0.679      0.586      0.644      0.433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/10         0G      1.097      1.087      1.312         54        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 225/225 [31:05<00:00,  8.29s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:57<00:00,  4.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        400       1203      0.757      0.644      0.718      0.495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/10         0G      1.054      1.017      1.282         38        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 225/225 [31:03<00:00,  8.28s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:56<00:00,  4.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        400       1203      0.765      0.607      0.704      0.497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/10         0G      1.024     0.9618       1.25         48        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 225/225 [31:00<00:00,  8.27s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:55<00:00,  4.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        400       1203      0.749      0.657      0.733      0.517\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/10         0G      1.002     0.9304      1.233         67        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 225/225 [31:02<00:00,  8.28s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:57<00:00,  4.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        400       1203      0.746      0.638      0.724      0.516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/10         0G     0.9833     0.9096      1.212         37        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 225/225 [31:11<00:00,  8.32s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:56<00:00,  4.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        400       1203      0.742      0.647      0.725      0.516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/10         0G     0.9715     0.8886      1.211         29        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 225/225 [31:10<00:00,  8.31s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:56<00:00,  4.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        400       1203      0.785      0.654      0.739      0.521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/10         0G     0.9619     0.8612      1.196         56        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 225/225 [30:54<00:00,  8.24s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:56<00:00,  4.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        400       1203      0.767      0.667      0.735      0.527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/10         0G     0.9469     0.8517      1.191         41        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 225/225 [31:05<00:00,  8.29s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:56<00:00,  4.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        400       1203      0.776      0.657      0.734      0.525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/10         0G     0.9402     0.8262      1.178         39        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 225/225 [31:13<00:00,  8.33s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:56<00:00,  4.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        400       1203      0.767       0.66      0.739      0.527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "10 epochs completed in 5.345 hours.\n",
      "Optimizer stripped from /Users/admin/runs/detect/train_large_new_final/weights/last.pt, 5.5MB\n",
      "Optimizer stripped from /Users/admin/runs/detect/train_large_new_final/weights/best.pt, 5.5MB\n",
      "\n",
      "Validating /Users/admin/runs/detect/train_large_new_final/weights/best.pt...\n",
      "Ultralytics 8.3.115 üöÄ Python-3.11.4 torch-2.2.2 CPU (Intel Core(TM) i7-8559U 2.70GHz)\n",
      "YOLO11n summary (fused): 100 layers, 2,582,932 parameters, 0 gradients, 6.3 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:49<00:00,  3.81s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        400       1203      0.767      0.666      0.736      0.527\n",
      "                   Car        167        592      0.667      0.537      0.588       0.39\n",
      "                  Taxi        104        298      0.779      0.641      0.755      0.486\n",
      "                 Truck        103        136      0.847      0.728      0.816      0.614\n",
      "                   Bus        101        177      0.776      0.757      0.782       0.62\n",
      "Speed: 3.0ms preprocess, 97.1ms inference, 0.0ms loss, 1.9ms postprocess per image\n",
      "Results saved to \u001b[1m/Users/admin/runs/detect/train_large_new_final\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# T·∫£i m√¥ h√¨nh ƒë√£ hu·∫•n luy·ªán\n",
    "model = YOLO(\"/Users/admin/runs/detect/train_large_new_extended_2/weights/last.pt\")\n",
    "\n",
    "# Hu·∫•n luy·ªán l·∫ßn cu·ªëi\n",
    "results = model.train(\n",
    "    data=\"/Users/admin/Car-detection-serving-model/open_images_project/dataset/data.yaml\",\n",
    "    epochs=10,  # 10 epochs\n",
    "    imgsz=640,  # TƒÉng t·ª´ 416 l√™n 640\n",
    "    batch=16,\n",
    "    device=\"cpu\",\n",
    "    optimizer=\"AdamW\",  # √âp d√πng AdamW\n",
    "    lr0=0.0005,  # C·ªë ƒë·ªãnh learning rate\n",
    "    name=\"train_large_new_final\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/0044141d3732acc5.jpg: 640x640 6 Cars, 337.7ms\n",
      "image 2/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/006f44b210255845.jpg: 448x640 2 Buss, 228.5ms\n",
      "image 3/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/007cdb3928bcfdb2.jpg: 448x640 2 Cars, 1 Taxi, 391.1ms\n",
      "image 4/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/007cdfad5b85d3e7.jpg: 640x448 1 Truck, 1 Bus, 233.3ms\n",
      "image 5/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/009b067a652d7d79.jpg: 608x640 1 Bus, 180.5ms\n",
      "image 6/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/00ef407e5b2ef618.jpg: 448x640 1 Bus, 132.7ms\n",
      "image 7/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/01133647412c00b0.jpg: 480x640 1 Car, 172.5ms\n",
      "image 8/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/0121a4ae057b374a.jpg: 448x640 1 Truck, 363.9ms\n",
      "image 9/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/015164ace6056778.jpg: 480x640 1 Bus, 178.6ms\n",
      "image 10/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/015b98ddab1cf750.jpg: 480x640 1 Truck, 170.4ms\n",
      "image 11/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/0166f14db9aa1a7c.jpg: 480x640 1 Truck, 117.4ms\n",
      "image 12/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/01fb8b5325e992d9.jpg: 384x640 2 Buss, 120.9ms\n",
      "image 13/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/020918cc8a1ffad1.jpg: 480x640 4 Buss, 124.4ms\n",
      "image 14/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/0210e348118a6edb.jpg: 480x640 1 Truck, 118.3ms\n",
      "image 15/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/023b2c4278240bc6.jpg: 512x640 4 Buss, 223.8ms\n",
      "image 16/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/02512b320806e9a7.jpg: 448x640 1 Taxi, 150.0ms\n",
      "image 17/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/0270cfc8a9268ebc.jpg: 448x640 2 Trucks, 129.3ms\n",
      "image 18/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/02c124bf9d2e7b35.jpg: 480x640 1 Truck, 1 Bus, 121.0ms\n",
      "image 19/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/02fa64986fef623f.jpg: 480x640 2 Buss, 145.1ms\n",
      "image 20/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/0327e6e1eea685b5.jpg: 448x640 4 Cars, 3 Taxis, 239.0ms\n",
      "image 21/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/0350b466f650c879.jpg: 480x640 1 Car, 272.2ms\n",
      "image 22/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/046f330dd62217a4.jpg: 480x640 1 Bus, 128.7ms\n",
      "image 23/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/04a2d6fd428bfd81.jpg: 480x640 2 Trucks, 172.9ms\n",
      "image 24/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/04de179b3294aaa0.jpg: 384x640 8 Cars, 4 Taxis, 126.7ms\n",
      "image 25/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/04e6d1b63a6f43ca.jpg: 416x640 1 Car, 149.9ms\n",
      "image 26/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/0507cbf593189c8c.jpg: 640x640 3 Trucks, 157.6ms\n",
      "image 27/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/05c700ad029a2f4a.jpg: 448x640 1 Car, 1 Taxi, 133.5ms\n",
      "image 28/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/06e147bb0c2a1fbe.jpg: 640x448 1 Car, 2 Taxis, 144.6ms\n",
      "image 29/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/074ff87a359f3dfe.jpg: 416x640 3 Cars, 1 Taxi, 110.5ms\n",
      "image 30/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/0773dd2b2a6d6164.jpg: 448x640 1 Car, 2 Taxis, 159.1ms\n",
      "image 31/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/0786212bde3d2c9c.jpg: 640x640 1 Truck, 180.4ms\n",
      "image 32/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/0787c08a48f43414.jpg: 640x480 3 Cars, 1 Taxi, 1 Bus, 131.8ms\n",
      "image 33/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/07bcd6f7e1c3ea6a.jpg: 448x640 1 Truck, 150.5ms\n",
      "image 34/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/080840a776ee37f3.jpg: 640x448 8 Taxis, 125.0ms\n",
      "image 35/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/08087292607240ac.jpg: 480x640 2 Buss, 143.7ms\n",
      "image 36/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/088f84c9ee2b827d.jpg: 480x640 2 Cars, 2 Taxis, 112.7ms\n",
      "image 37/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/08ed786ece7201f3.jpg: 480x640 4 Cars, 5 Taxis, 142.3ms\n",
      "image 38/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/09703e31dffe3ac8.jpg: 480x640 5 Cars, 131.2ms\n",
      "image 39/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/09b7224945d7718b.jpg: 384x640 5 Cars, 112.5ms\n",
      "image 40/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/09e8abefd741a918.jpg: 448x640 3 Cars, 1 Taxi, 112.9ms\n",
      "image 41/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/0a15e6d13aa9ab67.jpg: 480x640 1 Taxi, 130.9ms\n",
      "image 42/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/0ad1a51511ffa541.jpg: 480x640 5 Taxis, 115.8ms\n",
      "image 43/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/0bd755fe0e83f11a.jpg: 480x640 1 Bus, 114.3ms\n",
      "image 44/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/0c54950f475f8b3e.jpg: 480x640 1 Bus, 113.6ms\n",
      "image 45/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/0c9a8c4ab95b8546.jpg: 480x640 1 Bus, 113.9ms\n",
      "image 46/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/0ca61e55ccf257ba.jpg: 640x544 2 Trucks, 151.2ms\n",
      "image 47/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/0ca6278710e10d52.jpg: 480x640 6 Cars, 123.1ms\n",
      "image 48/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/0da8020bff4bed8a.jpg: 448x640 1 Car, 114.8ms\n",
      "image 49/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/0e38e721cd350cf7.jpg: 480x640 1 Car, 120.4ms\n",
      "image 50/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/0e922de92a69a483.jpg: 640x640 1 Car, 156.5ms\n",
      "image 51/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/0ed5cb3932fb7a58.jpg: 480x640 2 Cars, 6 Taxis, 118.2ms\n",
      "image 52/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/0f8f35116661df63.jpg: 640x640 1 Truck, 156.0ms\n",
      "image 53/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/0fcfbf0a39acdc22.jpg: 448x640 2 Buss, 118.5ms\n",
      "image 54/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/10949bc00db96f67.jpg: 480x640 1 Bus, 122.9ms\n",
      "image 55/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/10c1cf6e296a4c81.jpg: 480x640 1 Car, 1 Taxi, 117.5ms\n",
      "image 56/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/11826df64ba7d060.jpg: 640x608 1 Truck, 158.4ms\n",
      "image 57/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/12d6b9effc16d109.jpg: 448x640 3 Trucks, 119.3ms\n",
      "image 58/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/12deb1cd299d885d.jpg: 640x480 3 Cars, 2 Taxis, 124.8ms\n",
      "image 59/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/1359b011ba00fd66.jpg: 480x640 6 Cars, 1 Taxi, 124.5ms\n",
      "image 60/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/14a6d5c129f7e896.jpg: 448x640 (no detections), 113.6ms\n",
      "image 61/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/14cb07c67a70c4c5.jpg: 480x640 1 Bus, 124.4ms\n",
      "image 62/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/14e5c93e3a1eb813.jpg: 448x640 5 Buss, 113.3ms\n",
      "image 63/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/1538710ef148cbb0.jpg: 480x640 1 Truck, 150.0ms\n",
      "image 64/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/155ecabecefd9487.jpg: 448x640 2 Buss, 115.2ms\n",
      "image 65/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/161dcc822b96052f.jpg: 384x640 2 Cars, 2 Taxis, 111.1ms\n",
      "image 66/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/16e74af777bf8925.jpg: 640x480 2 Trucks, 122.2ms\n",
      "image 67/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/17d678eaaa88174a.jpg: 448x640 2 Cars, 113.5ms\n",
      "image 68/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/1899e4f5fe0b1075.jpg: 448x640 1 Car, 106.9ms\n",
      "image 69/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/18d6856aa125b358.jpg: 640x640 1 Bus, 155.8ms\n",
      "image 70/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/197a63ba525eb24c.jpg: 576x640 1 Bus, 154.9ms\n",
      "image 71/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/19a66bc340188ba5.jpg: 352x640 1 Car, 125.3ms\n",
      "image 72/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/1a21044d1fd26b4f.jpg: 448x640 2 Taxis, 124.3ms\n",
      "image 73/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/1a50afec445de1fd.jpg: 448x640 1 Car, 116.8ms\n",
      "image 74/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/1ba9a0c1f51bb6e6.jpg: 384x640 3 Cars, 112.2ms\n",
      "image 75/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/1c5bd1286e0ea51c.jpg: 480x640 4 Cars, 123.7ms\n",
      "image 76/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/1ce4f78534c54bc2.jpg: 448x640 1 Bus, 111.7ms\n",
      "image 77/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/1e10eb3601f6d242.jpg: 448x640 3 Cars, 135.1ms\n",
      "image 78/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/1e9e3a9b67c29c4c.jpg: 480x640 1 Car, 123.4ms\n",
      "image 79/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/1fd80240046ef704.jpg: 480x640 1 Bus, 114.7ms\n",
      "image 80/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/20769896afaacfd6.jpg: 480x640 5 Cars, 1 Taxi, 112.5ms\n",
      "image 81/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/21a8b07d4fac5d83.jpg: 640x448 2 Buss, 117.5ms\n",
      "image 82/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/21fa5e559adfb874.jpg: 480x640 3 Cars, 3 Taxis, 122.4ms\n",
      "image 83/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/2291ee87165169ac.jpg: 544x640 4 Cars, 3 Taxis, 158.1ms\n",
      "image 84/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/2308da1c44299d74.jpg: 640x448 2 Cars, 121.3ms\n",
      "image 85/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/2317ce89a2aa8b4e.jpg: 480x640 1 Bus, 127.2ms\n",
      "image 86/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/234ded5072612706.jpg: 448x640 1 Car, 7 Taxis, 114.4ms\n",
      "image 87/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/236ddbcdfcd2a897.jpg: 640x640 1 Truck, 1 Bus, 157.9ms\n",
      "image 88/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/26aececb0518d3b0.jpg: 448x640 3 Cars, 111.6ms\n",
      "image 89/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/271fc25212e632f6.jpg: 480x640 1 Truck, 124.7ms\n",
      "image 90/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/272d06ba697c737a.jpg: 448x640 1 Truck, 114.2ms\n",
      "image 91/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/273f309b205d7262.jpg: 480x640 1 Truck, 123.1ms\n",
      "image 92/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/27e00fe36ad079e6.jpg: 448x640 3 Cars, 116.2ms\n",
      "image 93/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/27e5412631899f81.jpg: 448x640 1 Truck, 106.0ms\n",
      "image 94/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/2892698e1ff99808.jpg: 640x480 1 Bus, 125.0ms\n",
      "image 95/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/2a15fecb1cf2ad7c.jpg: 512x640 1 Bus, 128.6ms\n",
      "image 96/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/2b338595c1a3a278.jpg: 480x640 1 Taxi, 122.3ms\n",
      "image 97/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/2cd60760a9203906.jpg: 480x640 3 Trucks, 121.0ms\n",
      "image 98/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/2d2405d13315965a.jpg: 448x640 2 Cars, 116.1ms\n",
      "image 99/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/2d6aec5ef27c7d74.jpg: 480x640 5 Cars, 121.2ms\n",
      "image 100/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/2d82ec4f3e125bcc.jpg: 480x640 1 Truck, 113.1ms\n",
      "image 101/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/2db70102be1f90c8.jpg: 480x640 1 Truck, 115.9ms\n",
      "image 102/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/2e7ed6a05a6b363b.jpg: 448x640 1 Car, 113.6ms\n",
      "image 103/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/2e8aead9715d529a.jpg: 448x640 3 Buss, 111.3ms\n",
      "image 104/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/2f87b0aed9d88fb4.jpg: 352x640 1 Bus, 105.6ms\n",
      "image 105/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/2f9d78c077cd3a55.jpg: 640x480 1 Bus, 123.9ms\n",
      "image 106/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/308ab5d8f9a38cac.jpg: 480x640 1 Truck, 119.7ms\n",
      "image 107/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/30c31c2e46364bbd.jpg: 480x640 1 Bus, 112.9ms\n",
      "image 108/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/3139af2f3e6f8bd0.jpg: 480x640 2 Buss, 116.0ms\n",
      "image 109/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/315f4596e8d92143.jpg: 224x640 2 Trucks, 95.5ms\n",
      "image 110/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/329b353602713c7c.jpg: 640x640 1 Car, 162.7ms\n",
      "image 111/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/32b83008b83e5d68.jpg: 480x640 1 Truck, 126.1ms\n",
      "image 112/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/32cc48b60184ec89.jpg: 448x640 1 Truck, 127.3ms\n",
      "image 113/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/339009178b243b31.jpg: 480x640 2 Trucks, 151.8ms\n",
      "image 114/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/348aa9b60f90f93f.jpg: 480x640 1 Car, 2 Taxis, 162.7ms\n",
      "image 115/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/351f124774df1720.jpg: 384x640 1 Truck, 122.1ms\n",
      "image 116/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/35440f3c9e6e3d8c.jpg: 640x608 4 Buss, 194.7ms\n",
      "image 117/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/362fa4d1986af8e9.jpg: 640x480 22 Taxis, 124.6ms\n",
      "image 118/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/36862a227dfbbf4f.jpg: 448x640 4 Cars, 4 Taxis, 137.9ms\n",
      "image 119/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/36d47d73f212e37f.jpg: 448x640 2 Trucks, 122.7ms\n",
      "image 120/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/37d4690414aaee60.jpg: 448x640 1 Bus, 175.4ms\n",
      "image 121/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/3839ed400cce5e53.jpg: 640x448 1 Car, 7 Taxis, 116.5ms\n",
      "image 122/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/388d01330b3b39ef.jpg: 480x640 2 Buss, 123.4ms\n",
      "image 123/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/38b315fb5ec8ce9c.jpg: 288x640 4 Cars, 111.7ms\n",
      "image 124/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/3967e7c4900084d6.jpg: 480x640 2 Buss, 163.4ms\n",
      "image 125/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/3989ee368408c307.jpg: 480x640 1 Truck, 120.0ms\n",
      "image 126/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/39a09bd1aad0094f.jpg: 416x640 1 Car, 111.1ms\n",
      "image 127/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/3a56afe7186f7b29.jpg: 224x640 2 Cars, 78.9ms\n",
      "image 128/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/3a6d56285f03a223.jpg: 480x640 5 Cars, 124.5ms\n",
      "image 129/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/3b16db1ed9d7915a.jpg: 448x640 1 Truck, 118.2ms\n",
      "image 130/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/3b8adfb83f89a7d4.jpg: 448x640 1 Truck, 143.4ms\n",
      "image 131/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/3bdfc04f7310c6ff.jpg: 480x640 5 Cars, 130.3ms\n",
      "image 132/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/3cef2522b36f8c57.jpg: 640x480 3 Cars, 125.6ms\n",
      "image 133/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/3cfcb4fce67ebcb9.jpg: 448x640 3 Buss, 193.9ms\n",
      "image 134/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/3d3d5ed32b90d345.jpg: 448x640 1 Bus, 160.1ms\n",
      "image 135/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/3d9a7412bd178cbf.jpg: 512x640 1 Car, 1 Taxi, 217.0ms\n",
      "image 136/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/3eb6b53d13eb65a4.jpg: 480x640 2 Buss, 210.7ms\n",
      "image 137/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/3f4e503184a49931.jpg: 448x640 2 Taxis, 162.1ms\n",
      "image 138/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/3f66ac951c5ab4f6.jpg: 480x640 3 Cars, 1 Taxi, 122.2ms\n",
      "image 139/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/42fb35583e220e23.jpg: 480x640 1 Truck, 1 Bus, 113.5ms\n",
      "image 140/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/4360d248ba002a97.jpg: 448x640 1 Car, 115.1ms\n",
      "image 141/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/4392e72478e73f74.jpg: 384x640 1 Bus, 117.7ms\n",
      "image 142/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/44e105aa319c8ca9.jpg: 448x640 1 Truck, 111.4ms\n",
      "image 143/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/46af16c83e28c272.jpg: 640x544 1 Taxi, 1 Bus, 131.7ms\n",
      "image 144/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/47b09b34e24b4039.jpg: 416x640 2 Buss, 108.6ms\n",
      "image 145/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/47ec7d53048550c3.jpg: 448x640 7 Cars, 2 Taxis, 111.8ms\n",
      "image 146/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/485a542db5576a98.jpg: 480x640 1 Taxi, 1 Bus, 117.9ms\n",
      "image 147/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/487c768e1be2a318.jpg: 448x640 1 Bus, 112.2ms\n",
      "image 148/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/48f3581d6cd567a6.jpg: 480x640 1 Car, 144.8ms\n",
      "image 149/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/4983836d96c157ce.jpg: 480x640 1 Taxi, 119.1ms\n",
      "image 150/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/499af57e1a2a2ba5.jpg: 448x640 1 Car, 131.0ms\n",
      "image 151/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/499e6e29cbb25ee1.jpg: 480x640 8 Cars, 125.7ms\n",
      "image 152/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/4a17d97c1b46b0de.jpg: 480x640 1 Car, 1 Bus, 113.0ms\n",
      "image 153/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/4a3b199a2e75a2d1.jpg: 448x640 1 Car, 144.0ms\n",
      "image 154/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/4b3ae50ff5f0cce3.jpg: 640x640 1 Car, 170.0ms\n",
      "image 155/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/4b40a3a31af1eea5.jpg: 480x640 1 Car, 2 Taxis, 139.6ms\n",
      "image 156/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/4b53360a4b751072.jpg: 640x448 4 Cars, 112.0ms\n",
      "image 157/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/4b6568b5172b0834.jpg: 480x640 2 Buss, 117.1ms\n",
      "image 158/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/4c5887590ad20981.jpg: 416x640 1 Car, 1 Taxi, 108.0ms\n",
      "image 159/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/4cd6d27b38d24da3.jpg: 640x480 1 Car, 1 Taxi, 151.8ms\n",
      "image 160/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/4d75f2982930f1b2.jpg: 480x640 1 Car, 117.0ms\n",
      "image 161/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/4e81bd7254f5904f.jpg: 480x640 2 Cars, 114.4ms\n",
      "image 162/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/4f54e5ba148439a7.jpg: 480x640 2 Trucks, 111.2ms\n",
      "image 163/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/4f69467e7c1046f2.jpg: 448x640 10 Taxis, 111.6ms\n",
      "image 164/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/4fe05952c79bfd95.jpg: 480x640 2 Buss, 124.4ms\n",
      "image 165/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/505194709a4c3ba1.jpg: 480x640 1 Bus, 111.8ms\n",
      "image 166/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/505d002154e2de2e.jpg: 448x640 7 Taxis, 110.9ms\n",
      "image 167/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/506ab4471ac83b38.jpg: 640x640 1 Car, 1 Taxi, 150.3ms\n",
      "image 168/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/50de0ff74f39a16a.jpg: 384x640 2 Buss, 106.3ms\n",
      "image 169/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/53044d65e470e024.jpg: 448x640 1 Taxi, 108.8ms\n",
      "image 170/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/540b2e8ee3b3eb81.jpg: 480x640 1 Car, 119.7ms\n",
      "image 171/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/552d1be56e8b39c8.jpg: 448x640 7 Cars, 110.4ms\n",
      "image 172/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/552ea00f97702be3.jpg: 480x640 6 Cars, 2 Taxis, 117.1ms\n",
      "image 173/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/56105117ba7a0a34.jpg: 480x640 1 Bus, 116.5ms\n",
      "image 174/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/567cb2a73dbab7b6.jpg: 480x640 3 Trucks, 109.8ms\n",
      "image 175/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/56f99a7e1afb993c.jpg: 448x640 6 Taxis, 116.2ms\n",
      "image 176/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/57cea9f0afbdc53d.jpg: 480x640 1 Taxi, 115.4ms\n",
      "image 177/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/5bc1e1e628725704.jpg: 640x448 3 Cars, 1 Taxi, 112.4ms\n",
      "image 178/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/5bf8d5b197288aff.jpg: 448x640 2 Taxis, 113.6ms\n",
      "image 179/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/5d4bae9579df96df.jpg: 480x640 11 Cars, 121.4ms\n",
      "image 180/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/5db0bc986821a14d.jpg: 384x640 1 Bus, 109.7ms\n",
      "image 181/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/5df1bb6e75ca66b1.jpg: 480x640 1 Truck, 119.4ms\n",
      "image 182/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/5dff7e787b8a1ef1.jpg: 480x640 4 Cars, 3 Taxis, 112.0ms\n",
      "image 183/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/5e26d9438cb63f96.jpg: 480x640 1 Truck, 111.8ms\n",
      "image 184/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/5f11ced5b4932575.jpg: 384x640 4 Buss, 106.4ms\n",
      "image 185/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/5f9adba265a80e78.jpg: 480x640 1 Bus, 116.6ms\n",
      "image 186/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/60155fd14f054a89.jpg: 448x640 1 Car, 112.5ms\n",
      "image 187/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/6028c49070ee2b28.jpg: 416x640 6 Cars, 6 Taxis, 110.4ms\n",
      "image 188/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/6043d99497347992.jpg: 448x640 1 Truck, 109.7ms\n",
      "image 189/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/61010f9210fcea88.jpg: 448x640 2 Buss, 102.9ms\n",
      "image 190/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/6173993c7156dd16.jpg: 448x640 (no detections), 103.5ms\n",
      "image 191/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/61e2275761990246.jpg: 448x640 2 Buss, 118.6ms\n",
      "image 192/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/622d6666254ccb8d.jpg: 640x640 1 Car, 193.4ms\n",
      "image 193/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/62c94acd7377ec4c.jpg: 480x640 1 Car, 6 Taxis, 136.0ms\n",
      "image 194/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/632f00f6f6bbe25b.jpg: 448x640 5 Cars, 3 Taxis, 140.0ms\n",
      "image 195/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/6570f8d87f8900dc.jpg: 480x640 4 Cars, 1 Truck, 118.8ms\n",
      "image 196/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/65a6c4fe2daf86a6.jpg: 448x640 2 Trucks, 116.6ms\n",
      "image 197/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/67859169a0eafad0.jpg: 480x640 1 Car, 129.6ms\n",
      "image 198/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/6831412e9a8413ef.jpg: 480x640 5 Cars, 118.6ms\n",
      "image 199/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/695253f32258e62d.jpg: 512x640 3 Cars, 1 Taxi, 166.9ms\n",
      "image 200/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/695dc6a9b4035146.jpg: 256x640 1 Car, 6 Taxis, 119.0ms\n",
      "image 201/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/695e8b5e913ac8b7.jpg: 416x640 4 Cars, 166.0ms\n",
      "image 202/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/698ca7a82c05d571.jpg: 288x640 4 Taxis, 112.4ms\n",
      "image 203/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/6a37d536b1fe1580.jpg: 480x640 3 Buss, 123.3ms\n",
      "image 204/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/6a5e46712d139687.jpg: 640x480 2 Cars, 1 Taxi, 152.6ms\n",
      "image 205/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/6a68fca0f40ac836.jpg: 480x640 2 Cars, 125.0ms\n",
      "image 206/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/6b5730895e350389.jpg: 480x640 1 Bus, 114.2ms\n",
      "image 207/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/6bfa6d4cb145065b.jpg: 480x640 1 Bus, 117.3ms\n",
      "image 208/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/6cb2403fc943e730.jpg: 640x640 1 Bus, 197.2ms\n",
      "image 209/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/6cdaba1f6d13d526.jpg: 480x640 1 Bus, 152.0ms\n",
      "image 210/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/6ceb5b82c7a45446.jpg: 480x640 3 Cars, 143.9ms\n",
      "image 211/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/6d7790091f46ad20.jpg: 320x640 1 Bus, 138.6ms\n",
      "image 212/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/6df19bbdd2683097.jpg: 384x640 2 Cars, 1 Truck, 124.4ms\n",
      "image 213/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/6f196e442ef35982.jpg: 480x640 2 Cars, 3 Taxis, 168.0ms\n",
      "image 214/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/6f474186e8de7b64.jpg: 480x640 1 Truck, 141.4ms\n",
      "image 215/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/6fd76f37e3b0edf6.jpg: 480x640 1 Car, 126.1ms\n",
      "image 216/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/70d379952a280425.jpg: 448x640 2 Cars, 138.3ms\n",
      "image 217/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/70defe416079bd62.jpg: 448x640 1 Truck, 131.0ms\n",
      "image 218/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/7223a6e74f51ec33.jpg: 640x640 1 Car, 183.2ms\n",
      "image 219/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/722a7e49e4ef6fce.jpg: 640x640 1 Bus, 166.8ms\n",
      "image 220/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/72ff61c1d321e63f.jpg: 480x640 1 Taxi, 119.8ms\n",
      "image 221/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/737fb6f3db28a004.jpg: 384x640 1 Car, 116.0ms\n",
      "image 222/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/739479b7c5b8a5f1.jpg: 480x640 1 Bus, 124.0ms\n",
      "image 223/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/73c5dc85b64e2a41.jpg: 480x640 1 Taxi, 141.7ms\n",
      "image 224/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/74962d4156af3973.jpg: 416x640 3 Trucks, 128.8ms\n",
      "image 225/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/75696da40d2378c7.jpg: 448x640 8 Cars, 114.9ms\n",
      "image 226/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/76f725cae319be94.jpg: 480x640 8 Cars, 1 Taxi, 123.7ms\n",
      "image 227/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/7700e987fe4b466d.jpg: 448x640 2 Cars, 1 Taxi, 132.3ms\n",
      "image 228/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/7709aac22571f002.jpg: 640x448 2 Cars, 130.9ms\n",
      "image 229/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/78ce48d227c37b89.jpg: 416x640 1 Truck, 147.8ms\n",
      "image 230/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/7b5affbf295a017f.jpg: 448x640 1 Bus, 118.2ms\n",
      "image 231/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/7cc164d1aad25dc1.jpg: 416x640 2 Cars, 1 Taxi, 118.2ms\n",
      "image 232/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/7eeba9a868950614.jpg: 512x640 1 Car, 154.2ms\n",
      "image 233/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/7f5d9244508be957.jpg: 448x640 1 Truck, 148.0ms\n",
      "image 234/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/7fc0388c17673688.jpg: 448x640 1 Bus, 131.1ms\n",
      "image 235/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/800d75f6c7e9c521.jpg: 480x640 4 Taxis, 132.0ms\n",
      "image 236/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/808879c0f08bdd9b.jpg: 480x640 3 Buss, 119.8ms\n",
      "image 237/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/80a04b448cd7075c.jpg: 640x640 1 Truck, 187.5ms\n",
      "image 238/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/80bb2d0137f6d78c.jpg: 640x448 1 Bus, 129.8ms\n",
      "image 239/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/80c32fb4707c1952.jpg: 480x640 1 Bus, 137.1ms\n",
      "image 240/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/8413de0b3fa8a5a4.jpg: 640x480 1 Car, 126.9ms\n",
      "image 241/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/843b6931403ab27d.jpg: 480x640 1 Car, 210.4ms\n",
      "image 242/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/84ebf8ceed8544e6.jpg: 448x640 4 Cars, 162.4ms\n",
      "image 243/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/86dfd75e89edac1c.jpg: 352x640 1 Truck, 106.8ms\n",
      "image 244/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/87481544862804f0.jpg: 512x640 1 Bus, 147.9ms\n",
      "image 245/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/8769808a982a621e.jpg: 512x640 1 Truck, 157.3ms\n",
      "image 246/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/87c3fb4632cdddaa.jpg: 224x640 1 Bus, 92.1ms\n",
      "image 247/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/883ce1988da496cd.jpg: 480x640 2 Cars, 4 Taxis, 158.4ms\n",
      "image 248/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/893b38c56285d7fc.jpg: 640x480 2 Buss, 128.3ms\n",
      "image 249/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/89cce279e66256a0.jpg: 480x640 4 Cars, 193.1ms\n",
      "image 250/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/89eb16acf43df012.jpg: 448x640 1 Truck, 138.4ms\n",
      "image 251/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/8a294d55850942ff.jpg: 448x640 2 Cars, 1 Taxi, 117.1ms\n",
      "image 252/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/8a33eec9530bc36a.jpg: 640x480 1 Truck, 140.2ms\n",
      "image 253/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/8b447ad282537380.jpg: 448x640 1 Truck, 125.7ms\n",
      "image 254/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/8b5be55b210d1dfb.jpg: 448x640 1 Bus, 107.4ms\n",
      "image 255/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/8bba4c835ffba3cb.jpg: 480x640 1 Truck, 123.4ms\n",
      "image 256/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/8d164636e4448be8.jpg: 480x640 3 Buss, 116.9ms\n",
      "image 257/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/8d476cb3f82aa620.jpg: 384x640 1 Truck, 163.9ms\n",
      "image 258/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/8e0445fce2c56a20.jpg: 544x640 5 Cars, 150.7ms\n",
      "image 259/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/8e485abd366fc8c5.jpg: 448x640 1 Truck, 159.1ms\n",
      "image 260/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/8ea3c7a61a18d5c2.jpg: 448x640 6 Cars, 4 Taxis, 114.1ms\n",
      "image 261/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/9019eee46061479e.jpg: 448x640 7 Taxis, 124.1ms\n",
      "image 262/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/936f11c78116b807.jpg: 480x640 8 Cars, 132.4ms\n",
      "image 263/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/93dcf3f5b7ab28bc.jpg: 480x640 1 Car, 119.0ms\n",
      "image 264/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/940622021ec789cf.jpg: 480x640 1 Truck, 177.0ms\n",
      "image 265/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/94d272334142ce3f.jpg: 480x640 1 Bus, 190.2ms\n",
      "image 266/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/95422e05beae0b94.jpg: 640x448 1 Truck, 248.6ms\n",
      "image 267/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/96174a7f8d6d7405.jpg: 480x640 2 Cars, 121.2ms\n",
      "image 268/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/973e562faebe55bb.jpg: 448x640 1 Bus, 115.1ms\n",
      "image 269/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/978e8831076a56d5.jpg: 480x640 1 Truck, 129.6ms\n",
      "image 270/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/98d10e5018be6062.jpg: 480x640 3 Cars, 135.4ms\n",
      "image 271/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/9a1c72826a4bac5a.jpg: 448x640 2 Buss, 168.3ms\n",
      "image 272/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/9acb4321c59d50be.jpg: 480x640 1 Car, 1 Taxi, 131.3ms\n",
      "image 273/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/9ae91d1729a369d4.jpg: 448x640 1 Truck, 118.9ms\n",
      "image 274/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/9c93a7fd29457571.jpg: 480x640 2 Trucks, 133.4ms\n",
      "image 275/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/9cb37f6338629b29.jpg: 480x640 2 Cars, 260.1ms\n",
      "image 276/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/9ccd0a37f66bd3f0.jpg: 448x640 3 Cars, 282.4ms\n",
      "image 277/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/9ce94c132df5b8dc.jpg: 512x640 1 Truck, 176.5ms\n",
      "image 278/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/9e5740eccbf5382b.jpg: 480x640 13 Cars, 1 Taxi, 303.7ms\n",
      "image 279/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/9f7c36bca7610e73.jpg: 448x640 1 Bus, 222.0ms\n",
      "image 280/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/a0a0fcb17dd2a04e.jpg: 448x640 1 Truck, 151.4ms\n",
      "image 281/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/a0ddc80895693a2f.jpg: 416x640 1 Bus, 256.1ms\n",
      "image 282/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/a129b70bfa626bee.jpg: 640x640 1 Car, 3 Taxis, 318.3ms\n",
      "image 283/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/a17495d2be501298.jpg: 480x640 2 Cars, 463.8ms\n",
      "image 284/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/a1e0492c696b1d47.jpg: 640x544 1 Truck, 264.2ms\n",
      "image 285/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/a2068c9865f26ba2.jpg: 480x640 2 Cars, 1 Taxi, 172.7ms\n",
      "image 286/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/a2fcae03786041aa.jpg: 480x640 3 Buss, 133.0ms\n",
      "image 287/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/a3184d086f0f8360.jpg: 448x640 1 Car, 2 Taxis, 127.9ms\n",
      "image 288/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/a4ae5d6bab4123e8.jpg: 448x640 8 Cars, 1 Taxi, 120.6ms\n",
      "image 289/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/a4af780e4bf3306d.jpg: 480x640 1 Car, 128.1ms\n",
      "image 290/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/a51c4f48bd13df20.jpg: 448x640 3 Trucks, 356.5ms\n",
      "image 291/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/a57dad98027a889c.jpg: 288x640 1 Car, 324.9ms\n",
      "image 292/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/a7d913a9676ed88f.jpg: 480x640 1 Truck, 177.8ms\n",
      "image 293/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/a8b5fb43328173ec.jpg: 448x640 2 Trucks, 254.0ms\n",
      "image 294/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/a8c7ebef3353cb59.jpg: 384x640 2 Cars, 186.3ms\n",
      "image 295/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/a92de8f1965bc9ab.jpg: 448x640 1 Bus, 229.8ms\n",
      "image 296/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/a95bf6f53759100c.jpg: 448x640 4 Taxis, 164.4ms\n",
      "image 297/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/a9be45a8d67b1430.jpg: 448x640 1 Truck, 116.9ms\n",
      "image 298/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/a9cbd4910c5d9086.jpg: 576x640 1 Bus, 153.3ms\n",
      "image 299/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/aa0989c03fc43980.jpg: 416x640 1 Truck, 204.2ms\n",
      "image 300/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/ab19fa80310acef4.jpg: 288x640 3 Trucks, 109.4ms\n",
      "image 301/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/ab3b25b0fa3d658b.jpg: 448x640 2 Cars, 1 Taxi, 138.8ms\n",
      "image 302/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/ab86e97ca49ac43e.jpg: 448x640 3 Cars, 1 Taxi, 124.1ms\n",
      "image 303/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/abee389896c7e41a.jpg: 512x640 1 Car, 219.5ms\n",
      "image 304/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/ac528f100d40aa71.jpg: 448x640 1 Truck, 131.8ms\n",
      "image 305/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/ad0f7a366a7d9cbc.jpg: 384x640 2 Cars, 1 Taxi, 125.2ms\n",
      "image 306/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/ad70e970ee2d90fa.jpg: 640x640 1 Truck, 184.0ms\n",
      "image 307/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/ad9fbe9ed3130689.jpg: 448x640 1 Car, 178.5ms\n",
      "image 308/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/ae242d93909e7758.jpg: 480x640 1 Bus, 142.3ms\n",
      "image 309/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/af0beaf9644613af.jpg: 640x480 1 Car, 270.2ms\n",
      "image 310/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/af7d84cb89c9fd01.jpg: 480x640 1 Car, 132.8ms\n",
      "image 311/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/b14ce8291ab689a6.jpg: 448x640 1 Car, 144.5ms\n",
      "image 312/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/b3c05a8e496fb43a.jpg: 448x640 4 Taxis, 135.1ms\n",
      "image 313/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/b5d3d1ed6b303f42.jpg: 480x640 1 Truck, 124.5ms\n",
      "image 314/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/b655348df1f1ebfe.jpg: 448x640 3 Cars, 1 Taxi, 167.4ms\n",
      "image 315/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/b74325446c0c56df.jpg: 640x640 7 Cars, 1 Taxi, 158.6ms\n",
      "image 316/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/b7b1f1ace0f48795.jpg: 640x416 3 Cars, 128.8ms\n",
      "image 317/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/b8278bf4a1e9c76f.jpg: 480x640 1 Car, 1 Taxi, 129.5ms\n",
      "image 318/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/b876270cae3fcfd5.jpg: 640x640 3 Cars, 2 Taxis, 465.0ms\n",
      "image 319/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/b964cd083b3291c4.jpg: 640x480 1 Car, 231.6ms\n",
      "image 320/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/b9bfa471d04109d7.jpg: 448x640 2 Trucks, 127.9ms\n",
      "image 321/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/ba090e9bd14af105.jpg: 480x640 5 Buss, 221.6ms\n",
      "image 322/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/bad221bc6a40f4e3.jpg: 640x384 1 Bus, 182.2ms\n",
      "image 323/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/bb298d73301aff30.jpg: 416x640 6 Cars, 1 Taxi, 193.8ms\n",
      "image 324/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/bb2df303e129c063.jpg: 416x640 1 Bus, 134.8ms\n",
      "image 325/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/bfbb415295961721.jpg: 480x640 2 Buss, 229.1ms\n",
      "image 326/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/c034fc78daaab2d5.jpg: 448x640 1 Truck, 177.2ms\n",
      "image 327/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/c040debe908057db.jpg: 480x640 2 Buss, 122.7ms\n",
      "image 328/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/c05b548b96d7faf2.jpg: 480x640 2 Buss, 123.4ms\n",
      "image 329/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/c0b90822c14460a6.jpg: 640x416 1 Truck, 131.6ms\n",
      "image 330/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/c1256503b3dfdf0a.jpg: 416x640 3 Cars, 1 Taxi, 150.3ms\n",
      "image 331/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/c2367e7512065963.jpg: 480x640 2 Trucks, 262.2ms\n",
      "image 332/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/c2f63867e84ea1d5.jpg: 480x640 2 Cars, 135.4ms\n",
      "image 333/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/c4687bf873447f4c.jpg: 480x640 3 Cars, 3 Taxis, 139.0ms\n",
      "image 334/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/c50acfeeba8c3853.jpg: 480x640 2 Cars, 147.4ms\n",
      "image 335/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/c550808b2d6a9f18.jpg: 480x640 2 Taxis, 123.3ms\n",
      "image 336/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/c6943d847f34be4c.jpg: 480x640 (no detections), 138.3ms\n",
      "image 337/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/c7e0c818a2ae192b.jpg: 480x640 1 Bus, 165.5ms\n",
      "image 338/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/ca16b2045877f93e.jpg: 448x640 1 Bus, 129.9ms\n",
      "image 339/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/ca6da4284511c0fe.jpg: 480x640 4 Cars, 192.7ms\n",
      "image 340/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/cb7b1452dd5ffb2d.jpg: 640x480 5 Taxis, 217.1ms\n",
      "image 341/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/cbe213773e0ffbe8.jpg: 352x640 1 Truck, 113.6ms\n",
      "image 342/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/cc7d97ebf3fd7f7c.jpg: 352x640 1 Bus, 107.8ms\n",
      "image 343/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/cee285a679fb6c8f.jpg: 480x640 1 Car, 198.2ms\n",
      "image 344/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/cef5c345ad5925ed.jpg: 448x640 4 Cars, 1 Taxi, 163.7ms\n",
      "image 345/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/cfbd7f76964a598a.jpg: 640x384 4 Buss, 127.4ms\n",
      "image 346/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/cff36bcdbac46aed.jpg: 480x640 1 Truck, 186.6ms\n",
      "image 347/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/cffe89826f41f896.jpg: 640x480 2 Cars, 2 Taxis, 165.8ms\n",
      "image 348/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/d0905b23f3f1683a.jpg: 480x640 7 Cars, 294.7ms\n",
      "image 349/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/d1751d1df4bf6551.jpg: 544x640 1 Bus, 351.8ms\n",
      "image 350/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/d1900f687a41b5ca.jpg: 416x640 4 Cars, 186.7ms\n",
      "image 351/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/d24ec69e72d5c0c3.jpg: 480x640 2 Buss, 233.6ms\n",
      "image 352/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/d5672b9da0f5c252.jpg: 416x640 4 Buss, 179.3ms\n",
      "image 353/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/d639d6fc2ccd32d8.jpg: 480x640 1 Truck, 200.6ms\n",
      "image 354/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/d67b0b10c47e97e6.jpg: 448x640 1 Car, 3 Taxis, 159.3ms\n",
      "image 355/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/d71eef2eb202ebde.jpg: 448x640 1 Bus, 125.2ms\n",
      "image 356/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/d7bf628cc800c74a.jpg: 480x640 2 Cars, 148.7ms\n",
      "image 357/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/d7cd21b7eff0f030.jpg: 448x640 1 Bus, 152.1ms\n",
      "image 358/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/d9c1b95541559247.jpg: 512x640 1 Truck, 159.2ms\n",
      "image 359/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/da53ab001fc18a03.jpg: 448x640 1 Car, 140.1ms\n",
      "image 360/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/dc80e20919030650.jpg: 480x640 3 Cars, 150.1ms\n",
      "image 361/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/dd91119d2333addf.jpg: 480x640 4 Cars, 145.1ms\n",
      "image 362/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/ddea2ff16aefbbe8.jpg: 480x640 3 Cars, 1 Taxi, 146.4ms\n",
      "image 363/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/de212da34186f795.jpg: 480x640 1 Truck, 176.9ms\n",
      "image 364/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/de3cf4c877ff0964.jpg: 448x640 7 Cars, 1 Taxi, 176.5ms\n",
      "image 365/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/dea159bf351dce76.jpg: 480x640 2 Taxis, 179.3ms\n",
      "image 366/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/df35a52eb5793a3e.jpg: 416x640 1 Car, 133.7ms\n",
      "image 367/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/e1eb704915af36e0.jpg: 480x640 1 Bus, 127.9ms\n",
      "image 368/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/e406895a033b0cdb.jpg: 480x640 1 Truck, 133.8ms\n",
      "image 369/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/e485d17afba34382.jpg: 384x640 7 Cars, 1 Taxi, 144.8ms\n",
      "image 370/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/e4fa91f37ebf1f64.jpg: 640x448 1 Car, 129.1ms\n",
      "image 371/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/e6ee79d653c7bab2.jpg: 480x640 1 Car, 204.3ms\n",
      "image 372/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/e7e0470fda1c45e3.jpg: 480x640 2 Cars, 214.9ms\n",
      "image 373/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/e81ce2fca98fb2f9.jpg: 384x640 3 Cars, 129.5ms\n",
      "image 374/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/e8a2a51e75297966.jpg: 480x640 1 Truck, 212.0ms\n",
      "image 375/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/eb34a38e10f395b4.jpg: 480x640 2 Cars, 8 Taxis, 129.5ms\n",
      "image 376/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/eb4b5ddb4018aff4.jpg: 480x640 1 Car, 2 Buss, 115.7ms\n",
      "image 377/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/eb96770ad9282844.jpg: 640x576 2 Cars, 173.1ms\n",
      "image 378/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/ed2dd199f5657b6a.jpg: 448x640 2 Cars, 142.7ms\n",
      "image 379/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/f00b0a811802bdcb.jpg: 416x640 1 Car, 119.1ms\n",
      "image 380/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/f014bc6f000e13a2.jpg: 640x448 4 Cars, 1 Taxi, 125.7ms\n",
      "image 381/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/f2dd622e03138ff7.jpg: 640x640 2 Trucks, 159.5ms\n",
      "image 382/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/f436f20f088e816b.jpg: 480x640 4 Cars, 121.3ms\n",
      "image 383/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/f5707f8e3265f367.jpg: 480x640 3 Trucks, 1 Bus, 127.1ms\n",
      "image 384/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/f59cb766f6d3777d.jpg: 576x640 1 Car, 166.7ms\n",
      "image 385/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/f5cad4476d48f395.jpg: 480x640 1 Car, 124.9ms\n",
      "image 386/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/f60e1222edbac7b3.jpg: 480x640 1 Truck, 115.1ms\n",
      "image 387/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/f634dec94aa2c9c4.jpg: 480x640 4 Cars, 3 Taxis, 113.2ms\n",
      "image 388/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/f63f06df16824656.jpg: 640x448 2 Cars, 116.5ms\n",
      "image 389/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/f64b8eaf3c365191.jpg: 512x640 1 Car, 130.4ms\n",
      "image 390/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/f6d9382475766688.jpg: 448x640 5 Cars, 160.5ms\n",
      "image 391/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/f7a708834b9d4307.jpg: 448x640 1 Car, 3 Taxis, 136.9ms\n",
      "image 392/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/f7a7f0606c476d95.jpg: 384x640 1 Bus, 111.3ms\n",
      "image 393/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/f850dc4a39ecc58c.jpg: 480x640 6 Taxis, 136.3ms\n",
      "image 394/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/f8d8ece8ad045bea.jpg: 448x640 1 Truck, 145.5ms\n",
      "image 395/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/f8e8c9766b51bc02.jpg: 640x640 1 Truck, 183.8ms\n",
      "image 396/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/fa6bbb6780018435.jpg: 640x640 1 Car, 154.2ms\n",
      "image 397/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/faf306be9c26ec15.jpg: 448x640 1 Taxi, 1 Bus, 126.3ms\n",
      "image 398/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/fb89352d815e119c.jpg: 448x640 5 Cars, 4 Taxis, 109.5ms\n",
      "image 399/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/fc4e03844adba4ee.jpg: 384x640 1 Car, 136.7ms\n",
      "image 400/400 /Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val/ff90eb28ca0c8452.jpg: 544x640 1 Bus, 138.1ms\n",
      "Speed: 5.0ms preprocess, 147.5ms inference, 1.3ms postprocess per image at shape (1, 3, 544, 640)\n",
      "Results saved to \u001b[1m/Users/admin/runs/detect/train_large_new_final2\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "results = model.predict(\n",
    "    source=\"/Users/admin/Car-detection-serving-model/open_images_project/dataset/images/val\",\n",
    "    save=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ƒê√£ log artifacts v√†o MLflow\n",
      "ƒê√£ log metrics v√†o MLflow\n",
      "M√¥ h√¨nh ƒë√£ ƒë∆∞·ª£c ƒëƒÉng k√Ω v·ªõi version 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Registered model 'YOLOv11_Model' already exists. Creating a new version of this model...\n",
      "Created version '7' of model 'YOLOv11_Model'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model version 7 transitioned to Production stage\n",
      "Metrics t·ª´ results.csv:\n",
      "{'mAP50': 0.73854, 'mAP50-95': 0.52683, 'train_box_loss': 0.94022, 'val_box_loss': 1.08893}\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "import os\n",
    "import pandas as pd\n",
    "from ultralytics import YOLO\n",
    "from mlflow.tracking import MlflowClient\n",
    "from mlflow.models.signature import ModelSignature\n",
    "from mlflow.types.schema import Schema, TensorSpec\n",
    "import numpy as np\n",
    "\n",
    "# ƒê∆∞·ªùng d·∫´n\n",
    "train_dir = \"/Users/admin/runs/detect/train_large_new_final\"\n",
    "data_yaml = \"/Users/admin/Car-detection-serving-model/open_images_project/dataset/data.yaml\"\n",
    "model_path = \"/Users/admin/runs/detect/train_large_new_final/weights/best.pt\"\n",
    "results_path = \"/Users/admin/runs/detect/train_large_new_final/results.csv\"\n",
    "\n",
    "# Thi·∫øt l·∫≠p tracking URI v√† experiment\n",
    "mlflow.set_tracking_uri(\"sqlite:///mlruns.db\")\n",
    "mlflow.set_experiment(\"YOLOv11_Experiments\")\n",
    "\n",
    "# Ki·ªÉm tra file results.csv t·ªìn t·∫°i\n",
    "if not os.path.exists(results_path):\n",
    "    raise FileNotFoundError(f\"File {results_path} does not exist. Please run the training step first.\")\n",
    "\n",
    "# ƒê·ªçc metrics t·ª´ results.csv\n",
    "results_df = pd.read_csv(results_path)\n",
    "metrics_from_csv = {\n",
    "    \"mAP50\": results_df[\"metrics/mAP50(B)\"].iloc[-1],\n",
    "    \"mAP50-95\": results_df[\"metrics/mAP50-95(B)\"].iloc[-1],\n",
    "    \"train_box_loss\": results_df[\"train/box_loss\"].iloc[-1],\n",
    "    \"val_box_loss\": results_df[\"val/box_loss\"].iloc[-1]\n",
    "}\n",
    "\n",
    "# B·∫Øt ƒë·∫ßu m·ªôt run duy nh·∫•t ƒë·ªÉ log t·∫•t c·∫£ th√¥ng tin\n",
    "with mlflow.start_run(run_name=\"YOLOv11_Training_Final\") as run:\n",
    "    # Log tham s·ªë hu·∫•n luy·ªán\n",
    "    params = {\n",
    "        \"epochs\": 60,\n",
    "        \"imgsz\": 640,\n",
    "        \"batch\": 16,\n",
    "        \"optimizer\": \"AdamW\",\n",
    "        \"lr0\": 0.0005\n",
    "    }\n",
    "    mlflow.log_params(params)\n",
    "\n",
    "    # Log artifacts\n",
    "    mlflow.log_artifact(data_yaml)\n",
    "    mlflow.log_artifact(train_dir)\n",
    "    mlflow.log_artifact(model_path)\n",
    "    mlflow.log_artifact(results_path)\n",
    "    mlflow.log_artifact(\"/Users/admin/runs/detect/train_large_new_final/results.png\", \"training_plots\")\n",
    "    print(\"ƒê√£ log artifacts v√†o MLflow\")\n",
    "\n",
    "    # Log metrics t·ª´ results.csv\n",
    "    mlflow.log_metrics(metrics_from_csv)\n",
    "    print(\"ƒê√£ log metrics v√†o MLflow\")\n",
    "\n",
    "    # ƒê·ªãnh nghƒ©a signature th·ªß c√¥ng (n·∫øu c·∫ßn log m√¥ h√¨nh)\n",
    "    input_schema = Schema([TensorSpec(np.dtype(np.float32), (-1, 3, 640, 640))])\n",
    "    output_schema = Schema([TensorSpec(np.dtype(np.float32), (-1, -1))])\n",
    "    signature = ModelSignature(inputs=input_schema, outputs=output_schema)\n",
    "\n",
    "    # Log m√¥ h√¨nh b·∫±ng c√°ch log file best.pt (thay v√¨ mlflow.pytorch.log_model)\n",
    "    mlflow.log_artifact(model_path)\n",
    "\n",
    "    # ƒêƒÉng k√Ω m√¥ h√¨nh\n",
    "    model_uri = f\"runs:/{run.info.run_id}/model\"\n",
    "    model_name = \"YOLOv11_Model\"\n",
    "    result = mlflow.register_model(model_uri, model_name)\n",
    "    print(f\"M√¥ h√¨nh ƒë√£ ƒë∆∞·ª£c ƒëƒÉng k√Ω v·ªõi version {result.version}\")\n",
    "\n",
    "    # Th√™m tags\n",
    "    client = MlflowClient()\n",
    "    tags = {\n",
    "        \"model_type\": \"YOLOv11\",\n",
    "        \"task\": \"vehicle_detection\",\n",
    "        \"imgsz\": \"640\",\n",
    "        \"epochs\": \"60\",\n",
    "        \"optimizer\": \"AdamW\"\n",
    "    }\n",
    "    for key, value in tags.items():\n",
    "        client.set_model_version_tag(model_name, result.version, key, value)\n",
    "    client.set_registered_model_tag(model_name, \"description\", \"YOLOv11 model for vehicle detection\")\n",
    "\n",
    "    # Chuy·ªÉn stage Production n·∫øu mAP50 >= 0.7\n",
    "    mAP50 = metrics_from_csv[\"mAP50\"]\n",
    "    if mAP50 >= 0.7:\n",
    "        client.transition_model_version_stage(\n",
    "            name=model_name,\n",
    "            version=result.version,\n",
    "            stage=\"Production\"\n",
    "        )\n",
    "        print(f\"Model version {result.version} transitioned to Production stage\")\n",
    "\n",
    "# In k·∫øt qu·∫£ metrics cu·ªëi c√πng ƒë·ªÉ ki·ªÉm tra\n",
    "print(\"Metrics t·ª´ results.csv:\")\n",
    "print(metrics_from_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-05-03 22:47:46 +0700] [57051] [INFO] Starting gunicorn 23.0.0\n",
      "[2025-05-03 22:47:46 +0700] [57051] [INFO] Listening at: http://127.0.0.1:5001 (57051)\n",
      "[2025-05-03 22:47:46 +0700] [57051] [INFO] Using worker: sync\n",
      "[2025-05-03 22:47:46 +0700] [57052] [INFO] Booting worker with pid: 57052\n",
      "[2025-05-03 22:47:46 +0700] [57053] [INFO] Booting worker with pid: 57053\n",
      "[2025-05-03 22:47:46 +0700] [57054] [INFO] Booting worker with pid: 57054\n",
      "[2025-05-03 22:47:46 +0700] [57055] [INFO] Booting worker with pid: 57055\n",
      "^C\n",
      "\n",
      "Aborted!\n",
      "[2025-05-03 22:48:10 +0700] [57052] [INFO] Worker exiting (pid: 57052)\n",
      "[2025-05-03 22:48:10 +0700] [57055] [INFO] Worker exiting (pid: 57055)\n",
      "[2025-05-03 22:48:10 +0700] [57053] [INFO] Worker exiting (pid: 57053)\n",
      "[2025-05-03 22:48:10 +0700] [57054] [INFO] Worker exiting (pid: 57054)\n"
     ]
    }
   ],
   "source": [
    "# Ch·∫°y MLflow UI tr√™n port 5001 v·ªõi backend store m·ªõi\n",
    "!mlflow ui --backend-store-uri file:///Users/admin/Documents/Car-detection-serving-model/open_images_project/mlruns_new --port 5001"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolo_env_new",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
